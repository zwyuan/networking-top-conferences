<div id="prox-body" class="x-panel-body x-panel-body-default x-panel-body-default x-docked-noborder-top x-docked-noborder-right x-docked-noborder-bottom x-docked-noborder-left" style="overflow: auto; width: 938px; left: 0px; top: 0px; height: 12133px;"><div id="cf_layoutareaprox">
<div style="margin-left:10px; margin-top:10px; margin-right:10px; margin-bottom: 10px;">
<h5 style="margin-bottom:0px; margin-top:0px" class="medium-text">Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services</h5>
<h5 class="medium-text" style="margin-bottom:10px; margin-top:10px;">Table of Contents</h5>
<div style="clear:both">
<div style="margin-top:5px; margin-bottom: 10px;" class="small-text"><a href="citation.cfm?id=3081333&amp;picked=prox" title="previous: MobiSys '17"><img hspace="5" align="absmiddle" border="0" src="img/prev.gif" width="19" height="11" alt="previous">previous proceeding</a> <span style="padding-left:5px;padding-right:5px;">|</span><span class="link-text">no next proceeding</span></div>
</div>
<table class="text12" border="0">
<tbody><tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210334">SeCloak: ARM Trustzone-based Mobile Peripheral Control</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=83358860057">Matthew Lentz</a>,
<a href="author_page.cfm?id=81464651285">Rijurekha Sen</a>,
<a href="author_page.cfm?id=81100111742">Peter Druschel</a>,
<a href="author_page.cfm?id=81100556569">Bobby Bhattacharjee</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 1-13</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210334" title="DOI">10.1145/3210240.3210334</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210334&amp;ftid=1984447&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Other formats:
<a name="OtherFormatswebm" title="Other Formats webm" href="ft_gateway.cfm?id=3210334&amp;ftid=1992744&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/webm.jpg" alt="webm" class="fulltext_lnk" border="0">webm</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow1" style="display:inline;"><br><div style="display:inline">Reliable on-off control of peripherals on smart devices is a key to security and privacy in many scenarios. Journalists want to reliably turn off radios to protect their sources during investigative reporting. Users wish to ensure cameras and microphones ...</div></span>
<span id="toHide1" style="display:none;"><br><div style="display:inline"><p>Reliable on-off control of peripherals on smart devices is a key to security and privacy in many scenarios. Journalists want to reliably turn off radios to protect their sources during investigative reporting. Users wish to ensure cameras and microphones are reliably off during private meetings. In this paper, we present SeCloak, an ARM TrustZone-based solution that ensures reliable on-off control of peripherals even when the platform software is compromised. We design a secure kernel that co-exists with software running on mobile devices (e.g., Android and Linux) without requiring any code modifications. An Android prototype demonstrates that mobile peripherals like radios, cameras, and microphones can be controlled reliably with a very small trusted computing base and with minimal performance overhead.</p></div></span> <a id="expcoll1" href="JavaScript: expandcollapse('expcoll1',1)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210338">TruZ-Droid: Integrating TrustZone with Mobile Operating System</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99658658273">Kailiang Ying</a>,
<a href="author_page.cfm?id=86159162757">Amit Ahlawat</a>,
<a href="author_page.cfm?id=99659282967">Bilal Alsharifi</a>,
<a href="author_page.cfm?id=99659282981">Yuexin Jiang</a>,
<a href="author_page.cfm?id=99659282331">Priyank Thavai</a>,
<a href="author_page.cfm?id=99659283675">Wenliang Du</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 14-27</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210338" title="DOI">10.1145/3210240.3210338</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210338&amp;ftid=1984494&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Other formats:
<a name="OtherFormatswebm" title="Other Formats webm" href="ft_gateway.cfm?id=3210338&amp;ftid=1992755&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/webm.jpg" alt="webm" class="fulltext_lnk" border="0">webm</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow2" style="display:inline;"><br><div style="display:inline">Mobile devices today provide a hardware-protected mode called Trusted Execution Environment (TEE) to help protect users from a compromised OS and hypervisor. Today TEE can only be leveraged either by vendor apps or by developers who work with the vendor. ...</div></span>
<span id="toHide2" style="display:none;"><br><div style="display:inline"><p>Mobile devices today provide a hardware-protected mode called Trusted Execution Environment (TEE) to help protect users from a compromised OS and hypervisor. Today TEE can only be leveraged either by vendor apps or by developers who work with the vendor. Since vendors consider third-party app code untrusted inside the TEE, to allow an app to leverage TEE, app developers have to write the app code in a tailored way to work with the vendor's SDK. We proposed a novel design to integrate TEE with mobile OS to allow any app to leverage the TEE. Our design incorporates TEE support at the OS level, allowing apps to leverage the TEE without adding app-specific code into the TEE, and while using existing interface to interact with the mobile OS. We implemented our design, called TruZ-Droid, by integrating TrustZone TEE with the Android OS. TruZ-Droid allows apps to leverage the TEE to protect the following: (i) user's secret input and confirmation, and (ii) sending of user's secrets to the authorized server. We built a prototype using the TrustZone-enabled HiKey board to evaluate our design. We demonstrated TruZ-Droid's effectiveness by adding new security features to existing apps to protect user's sensitive information and attest user's confirmation. TruZ-Droid's real-world use case evaluation shows that apps can leverage TrustZone while using existing OS APIs. Our usability study proves that users can correctly interact with TruZ-Droid to protect their security sensitive activities and data.</p></div></span> <a id="expcoll2" href="JavaScript: expandcollapse('expcoll2',2)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210330">VButton: Practical Attestation of User-driven Operations in Mobile Apps</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99658633354">Wenhao Li</a>,
<a href="author_page.cfm?id=99659283611">Shiyu Luo</a>,
<a href="author_page.cfm?id=99659282937">Zhichuang Sun</a>,
<a href="author_page.cfm?id=82259189557">Yubin Xia</a>,
<a href="author_page.cfm?id=99659284826">Long Lu</a>,
<a href="author_page.cfm?id=81550163356">Haibo Chen</a>,
<a href="author_page.cfm?id=81323498664">Binyu Zang</a>,
<a href="author_page.cfm?id=81336489541">Haibing Guan</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 28-40</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210330" title="DOI">10.1145/3210240.3210330</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210330&amp;ftid=1984468&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Other formats:
<a name="OtherFormatswebm" title="Other Formats webm" href="ft_gateway.cfm?id=3210330&amp;ftid=1992756&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/webm.jpg" alt="webm" class="fulltext_lnk" border="0">webm</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow3" style="display:inline;"><br><div style="display:inline">More and more malicious apps and mobile rootkits are found to perform sensitive operations on behalf of legitimate users without their awareness. Malware does so by either forging user inputs or tricking users into making unintended requests to online ...</div></span>
<span id="toHide3" style="display:none;"><br><div style="display:inline"><p>More and more malicious apps and mobile rootkits are found to perform sensitive operations on behalf of legitimate users without their awareness. Malware does so by either forging user inputs or tricking users into making unintended requests to online service providers. Such malware is hard to detect and generates large revenues for cybercriminals, which is often used for committing ad/click frauds, faking reviews/ratings, promoting people or business on social networks, etc.</p> <p>We find that this class of malware is possible due to the lack of practical and robust means for service providers to verify the authenticity of user-driven operations (i.e., operations supposed to be performed, or explicitly confirmed, by a user). We design and build the VButton system to fill this void. Our system introduces a class of attestation-enabled app UI widgets (called VButton UI). Developers can easily integrate VButton UI in their apps to allow service providers to verify that a user-driven operation triggered by a VButton UI is indeed initiated and intended by a real user. Our system contains an on-device Manager, and a server-side Verifier. Leveraging ARM TrustZone, our system can attest operation authenticity even in the presence of a compromised OS. We have implemented the VButton system on an ARM development board as well as a commercial off-the-shelf smartphone. The evaluation results show that the system incurs negligible overhead.</p></div></span> <a id="expcoll3" href="JavaScript: expandcollapse('expcoll3',3)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210317">Augmented Reality-based Mimicry Attacks on Behaviour-Based Smartphone Authentication</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=87658710857">Hassan Khan</a>,
<a href="author_page.cfm?id=81100043795">Urs Hengartner</a>,
<a href="author_page.cfm?id=81100054467">Daniel Vogel</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 41-53</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210317" title="DOI">10.1145/3210240.3210317</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210317&amp;ftid=1984507&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Other formats:
<a name="OtherFormatswebm" title="Other Formats webm" href="ft_gateway.cfm?id=3210317&amp;ftid=1992719&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/webm.jpg" alt="webm" class="fulltext_lnk" border="0">webm</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow4" style="display:inline;"><br><div style="display:inline">We develop an augmented reality-based app that resides on the attacker's smartphone and leverages computer vision and raw input data to provide real-time mimicry attack guidance on the victim's phone. Our approach does not require tampering or installing ...</div></span>
<span id="toHide4" style="display:none;"><br><div style="display:inline"><p>We develop an augmented reality-based app that resides on the attacker's smartphone and leverages computer vision and raw input data to provide real-time mimicry attack guidance on the victim's phone. Our approach does not require tampering or installing software on the victim's device, or specialized hardware. The app is demonstrated by attacking keystroke dynamics, a method leveraging the unique typing behaviour of users to authenticate them on a smartphone, which was previously thought to be hard to mimic. In addition, we propose a low-tech AR-like audiovisual method based on spatial pointers on a transparent film and audio cues. We conduct experiments with 31 participants and mount over 400 attacks to show that our methods enable attackers to successfully bypass keystroke dynamics for 87% of the attacks after an average mimicry training of four minutes. Our AR-based method can be extended to attack other input behaviour-based biometrics. While the particular attack we describe is relatively narrow, it is a good example of using AR guidance to enable successful mimicry of user behaviour---an approach of increasing concern as AR functionality becomes more commonplace.</p></div></span> <a id="expcoll4" href="JavaScript: expandcollapse('expcoll4',4)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210348">My Being to Your Place, Your Being to My Place: Co-present Robotic Avatars Create Illusion of Living Together</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99658690166">Bumsoo Kang</a>,
<a href="author_page.cfm?id=81410593113">Inseok Hwang</a>,
<a href="author_page.cfm?id=99659284549">Jinho Lee</a>,
<a href="author_page.cfm?id=99659283804">Seungchul Lee</a>,
<a href="author_page.cfm?id=99659282681">Taegyeong Lee</a>,
<a href="author_page.cfm?id=99659284382">Youngjae Chang</a>,
<a href="author_page.cfm?id=99659283293">Min Kyung Lee</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 54-67</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210348" title="DOI">10.1145/3210240.3210348</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210348&amp;ftid=1984448&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow5" style="display:inline;"><br><div style="display:inline">People in work-separated families have been heavily relying on cutting-edge face-to-face communication services. Despite their ease of use and ubiquitous availability, experiences in living together are still far incomparable to those through remote ...</div></span>
<span id="toHide5" style="display:none;"><br><div style="display:inline"><p>People in work-separated families have been heavily relying on cutting-edge face-to-face communication services. Despite their ease of use and ubiquitous availability, experiences in living together are still far incomparable to those through remote face-to-face communication. We envision that enabling a remote person to be spatially superposed in one's living space would be a breakthrough to catalyze pseudo living-together interactivity. We propose HomeMeld, a zero-hassle self-mobile robotic system serving as a co-present avatar to create a persistent illusion of living together for those who are involuntarily living apart. The key challenges are 1) continuous spatial mapping between two heterogeneous floor plans and 2) navigating the robotic avatar to reflect the other's presence in real time under the limited maneuverability of the robot. We devise a notion of functionally equivalent location and orientation to translate a person's presence into another in a heterogeneous floor plan. We also develop predictive path warping to seamlessly synchronize the presence of the other. We conducted extensive experiments and deployment studies with real participants.</p></div></span> <a id="expcoll5" href="JavaScript: expandcollapse('expcoll5',5)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210313">Cutting the Cord: Designing a High-quality Untethered VR System with Low Latency Remote Rendering</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99659198364">Luyang Liu</a>,
<a href="author_page.cfm?id=99659200039">Ruiguang Zhong</a>,
<a href="author_page.cfm?id=99659284828">Wuyang Zhang</a>,
<a href="author_page.cfm?id=81556399356">Yunxin Liu</a>,
<a href="author_page.cfm?id=99659283097">Jiansong Zhang</a>,
<a href="author_page.cfm?id=99659198433">Lintao Zhang</a>,
<a href="author_page.cfm?id=81100490340">Marco Gruteser</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 68-80</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210313" title="DOI">10.1145/3210240.3210313</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210313&amp;ftid=1984501&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Other formats:
<a name="OtherFormatswebm" title="Other Formats webm" href="ft_gateway.cfm?id=3210313&amp;ftid=1992723&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/webm.jpg" alt="webm" class="fulltext_lnk" border="0">webm</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow6" style="display:inline;"><br><div style="display:inline">This paper introduces an end-to-end untethered VR system design and open platform that can meet virtual reality latency and quality requirements at 4K resolution over a wireless link. High-quality VR systems generate graphics data at a data rate much ...</div></span>
<span id="toHide6" style="display:none;"><br><div style="display:inline"><p>This paper introduces an end-to-end untethered VR system design and open platform that can meet virtual reality latency and quality requirements at 4K resolution over a wireless link. High-quality VR systems generate graphics data at a data rate much higher than those supported by existing wireless-communication products such as Wi-Fi and 60GHz wireless communication. The necessary image encoding, makes it challenging to maintain the stringent VR latency requirements. To achieve the required latency, our system employs a Parallel Rendering and Streaming mechanism to reduce the add-on streaming latency, by pipelining the rendering, encoding, transmission and decoding procedures. Furthermore, we introduce a Remote VSync Driven Rendering technique to minimize display latency. To evaluate the system, we implement an end-to-end remote rendering platform on commodity hardware over a 60Ghz wireless network. Results show that the system can support current 2160x1200 VR resolution at 90Hz with less than 16ms end-to-end latency, and 4K resolution with 20ms latency, while keeping a visually lossless image quality to the user.</p></div></span> <a id="expcoll6" href="JavaScript: expandcollapse('expcoll6',6)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210319">AVR: Augmented Vehicular Reality</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99658654127">Hang Qiu</a>,
<a href="author_page.cfm?id=99659132292">Fawad Ahmad</a>,
<a href="author_page.cfm?id=81100633622">Fan Bai</a>,
<a href="author_page.cfm?id=81100490340">Marco Gruteser</a>,
<a href="author_page.cfm?id=81327488641">Ramesh Govindan</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 81-95</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210319" title="DOI">10.1145/3210240.3210319</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210319&amp;ftid=1984495&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Other formats:
<a name="OtherFormatswebm" title="Other Formats webm" href="ft_gateway.cfm?id=3210319&amp;ftid=1992724&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/webm.jpg" alt="webm" class="fulltext_lnk" border="0">webm</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow7" style="display:inline;"><br><div style="display:inline">Autonomous vehicle prototypes today come with line-of-sight depth perception sensors like 3D cameras. These 3D sensors are used for improving vehicular safety in autonomous driving, but have fundamentally limited visibility due to occlusions, sensing ...</div></span>
<span id="toHide7" style="display:none;"><br><div style="display:inline"><p>Autonomous vehicle prototypes today come with line-of-sight depth perception sensors like 3D cameras. These 3D sensors are used for improving vehicular safety in autonomous driving, but have fundamentally limited visibility due to occlusions, sensing range, and extreme weather and lighting conditions. To improve visibility and performance, not just for autonomous vehicles but for other Advanced Driving Assistance Systems (ADAS), we explore a capability called Augmented Vehicular Reality (AVR). AVR broadens the vehicle's visual horizon by enabling it to wirelessly share visual information with other nearby vehicles, but requires the design of novel relative positioning techniques, new perspective transformation methods, approaches to isolate and predict the motion of dynamic objects in order to hide latency, and adaptive transmission strategies to cope with wireless bandwidth variability. We show that AVR is feasible using off-the-shelf wireless technologies, and it can qualitatively change the decisions made by autonomous vehicle path planning algorithms. Our AVR prototype achieves positioning accuracies that are within a few percent of car lengths and lane widths, and is optimized to process frames at 30fps.</p></div></span> <a id="expcoll7" href="JavaScript: expandcollapse('expcoll7',7)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210339">Kite: Building Conversational Bots from Mobile Apps</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99659163126">Toby Jia-Jun Li</a>,
<a href="author_page.cfm?id=81339524621">Oriana Riva</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 96-109</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210339" title="DOI">10.1145/3210240.3210339</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210339&amp;ftid=1984449&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Other formats:
<a name="OtherFormatswebm" title="Other Formats webm" href="ft_gateway.cfm?id=3210339&amp;ftid=1992734&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/webm.jpg" alt="webm" class="fulltext_lnk" border="0">webm</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow8" style="display:inline;"><br><div style="display:inline">Task-oriented chatbots allow users to carry out tasks (e.g., ordering a pizza) using natural language conversation. The widely-used slot-filling approach for building bots of this type requires significant hand-coding, which hinders scalability. Recently, ...</div></span>
<span id="toHide8" style="display:none;"><br><div style="display:inline"><p>Task-oriented chatbots allow users to carry out tasks (e.g., ordering a pizza) using natural language conversation. The widely-used slot-filling approach for building bots of this type requires significant hand-coding, which hinders scalability. Recently, neural network models have been shown to be capable of generating natural "chitchat" conversations, but it is unclear whether they will ever work for task modeling. Kite is a practical system for bootstrapping task-oriented bots, leveraging both approaches above. Kite's key insight is that while bots encapsulate the logic of user tasks into conversational forms, existing apps encapsulate the logic of user tasks into graphical user interfaces. A developer demonstrates a task using a relevant app, and from the collected interaction traces Kite automatically derives a task model, a graph of actions and associated inputs representing possible task execution paths. A task model represents the logical backbone of a bot, on which Kite layers a question-answer interface generated using a hybrid rule-based and neural network approach. Using Kite, developers can automatically generate bot templates for many different tasks. In our evaluation, it extracted accurate task models from 25 popular Android apps spanning 15 tasks. Appropriate questions and high-quality answers were also generated. Our developer study suggests that developers, even without any bot developing experience, can successfully generate bot templates using Kite.</p></div></span> <a id="expcoll8" href="JavaScript: expandcollapse('expcoll8',8)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210327">RuntimeDroid: Restarting-Free Runtime Change Handling for Android Apps</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99659283539">Umar Farooq</a>,
<a href="author_page.cfm?id=81538929656">Zhijia Zhao</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 110-122</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210327" title="DOI">10.1145/3210240.3210327</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210327&amp;ftid=1984483&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Other formats:
<a name="OtherFormatswebm" title="Other Formats webm" href="ft_gateway.cfm?id=3210327&amp;ftid=1992745&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/webm.jpg" alt="webm" class="fulltext_lnk" border="0">webm</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow9" style="display:inline;"><br><div style="display:inline">Portable devices, like smartphones and tablets, are often subject to runtime configuration changes, such as screen orientation changes, screen resizing, keyboard attachments, and language switching. When handled improperly, such simple changes can cause ...</div></span>
<span id="toHide9" style="display:none;"><br><div style="display:inline"><p>Portable devices, like smartphones and tablets, are often subject to runtime configuration changes, such as screen orientation changes, screen resizing, keyboard attachments, and language switching. When handled improperly, such simple changes can cause serious runtime issues, from data loss to app crashes.</p> <p>This work presents, to our best knowledge, the first formative study on runtime change handling with 3,567 Android apps. The study not only reveals the current landscape of runtime change handling, but also points out a common cause of various runtime change issues -- activity restarting. On one hand, the restarting facilitates the resource reloading for the new configuration. On the other hand, it may slow down the app, and more critically, it requires developers to manually preserve a set of data in order to recover the user interaction state after restarting.</p> <p>Based on the findings of this study, this work further introduces a re starting-free runtime change handling solution -- RuntimeDroid. RuntimeDroid can completely avoid the activity restarting, at the same time, ensure proper resource updating with user input data preserved. These are achieved with two key components: an online resource loading module, called HotR and a novel UI components migration technique. The former enables proper resources loading while the activity is still live. The latter ensures that prior user changes are carefully preserved during runtime changes.</p> <p>For practical use, this work proposes two implementations of RuntimeDroid: an IDE plugin and an auto-patching tool. The former allows developers to easily adopt restarting-free runtime change handling during the app developing; The latter can patch released app packages without source code. Finally, evaluation with a set of 72 apps shows that RuntimeDroid successfully fixed all the 197 reported runtime change issues, meanwhile reducing the runtime change handling delays by 9.5X on average.</p></div></span> <a id="expcoll9" href="JavaScript: expandcollapse('expcoll9',9)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210331">Empath-D: VR-based Empathetic App Design for Accessibility</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99659071883">Wonjung Kim</a>,
<a href="author_page.cfm?id=99659052376">Kenny Tsu Wei Choo</a>,
<a href="author_page.cfm?id=99659132136">Youngki Lee</a>,
<a href="author_page.cfm?id=81100342304">Archan Misra</a>,
<a href="author_page.cfm?id=81100050092">Rajesh Krishna Balan</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 123-135</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210331" title="DOI">10.1145/3210240.3210331</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210331&amp;ftid=1984436&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow10" style="display:inline;"><br><div style="display:inline">With app-based interaction increasingly permeating all aspects of daily living, it is essential to ensure that apps are designed to be inclusive and are usable by a wider audience such as the elderly, with various impairments (e.g., visual, audio and ...</div></span>
<span id="toHide10" style="display:none;"><br><div style="display:inline"><p>With app-based interaction increasingly permeating all aspects of daily living, it is essential to ensure that apps are designed to be inclusive and are usable by a wider audience such as the elderly, with various impairments (e.g., visual, audio and motor). We propose Empath-D, a system that fosters empathetic design, by allowing app designers, in-situ, to rapidly evaluate the usability of their apps, from the perspective of impaired users. To provide a truly authentic experience, Empath-D carefully orchestrates the interaction between a smartphone and a VR device, allowing the user to experience simulated impairments in a virtual world while interacting naturally with the app, using a real smartphone. By carefully orchestrating the VR-smartphone interaction, Empath-D tackles challenges such as preserving low-latency app interaction, accurate visualization of hand movement and low-overhead perturbation of I/O streams. Experimental results show that user interaction with Empath-D is comparable (both in accuracy and user perception) to real-world app usage, and that it can simulate impairment effects as effectively as a custom hardware simulator.</p></div></span> <a id="expcoll10" href="JavaScript: expandcollapse('expcoll10',10)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210324">Sonoloc: Scalable positioning of commodity mobile devices</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=89558912157">Viktor Erd√©lyi</a>,
<a href="author_page.cfm?id=99659282583">Trung-Kien Le</a>,
<a href="author_page.cfm?id=81100556569">Bobby Bhattacharjee</a>,
<a href="author_page.cfm?id=81100111742">Peter Druschel</a>,
<a href="author_page.cfm?id=81375597674">Nobutaka Ono</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 136-149</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210324" title="DOI">10.1145/3210240.3210324</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210324&amp;ftid=1984484&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow11" style="display:inline;"><br><div style="display:inline">We present Sonoloc, a mobile app and system that allows a set of co-located commodity smart devices to determine their relative positions without local infrastructure. Sonoloc enables users to address each other based on their relative positions at events ...</div></span>
<span id="toHide11" style="display:none;"><br><div style="display:inline"><p>We present Sonoloc, a mobile app and system that allows a set of co-located commodity smart devices to determine their relative positions without local infrastructure. Sonoloc enables users to address each other based on their relative positions at events like meetings, talks, or conferences. This capability can, for instance, aid spontaneous communication among users based on their relative position (e.g., in a given section of a room, at the same table, or in a given seat), facilitate interaction between speaker and audience in a lecture hall, and enable the distribution of materials, crowdsensing, and feedback collection based on users' location. Sonoloc can position any number of devices within acoustic range with a constant number of chirps emitted by a self-organized subset of devices. Our experimental evaluation shows that the system can locate up to hundreds of devices with an accuracy of tens of centimeters using up to 15 audio chirps emitted by dynamically selected devices, in actual rooms and despite substantial background noise.</p></div></span> <a id="expcoll11" href="JavaScript: expandcollapse('expcoll11',11)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210316">BikeGPS: Accurate Localization of Shared Bikes in Street Canyons via Low-Level GPS Cooperation</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99659250781">Kongyang Chen</a>,
<a href="author_page.cfm?id=81508683061">Guang Tan</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 150-162</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210316" title="DOI">10.1145/3210240.3210316</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210316&amp;ftid=1984485&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Other formats:
<a name="OtherFormatswebm" title="Other Formats webm" href="ft_gateway.cfm?id=3210316&amp;ftid=1992725&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/webm.jpg" alt="webm" class="fulltext_lnk" border="0">webm</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow12" style="display:inline;"><br><div style="display:inline">The past few years have seen a surge of stationless bike sharing services in many modern cities. The service allows the bikes to be dropped off freely, and to be found through GPS localization. For maximum convenience, the bikes are often parked in close ...</div></span>
<span id="toHide12" style="display:none;"><br><div style="display:inline"><p>The past few years have seen a surge of stationless bike sharing services in many modern cities. The service allows the bikes to be dropped off freely, and to be found through GPS localization. For maximum convenience, the bikes are often parked in close proximity to the buildings, where GPS may perform poorly, making bike search a challenging task. This paper proposes a novel approach to addressing this problem. Inspired by multi-antenna systems, our method tries to collect GPS signals from multiple distributed bikes, by organizing a group of bikes into a network, called the BikeGPS. Formed by pedestrian users who opportunistically measure interbike distance via radio sensing and step tracking, the generated network permits one to map all the nodes' satellite range measurements into a single lead node's view. By considering both signal and geometry properties of satellite raw measurements, and using an asynchronous coarse time navigation algorithm, the lead node can accurately derive the locations of all the network nodes. Real-world experiments show that BikeGPS significantly improves the localization performance, in terms of both accuracy and solution availability, compared with the naive GPS approach and a high-level cooperative localization method.</p></div></span> <a id="expcoll12" href="JavaScript: expandcollapse('expcoll12',12)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210343">Gnome: A Practical Approach to NLOS Mitigation for GPS Positioning in Smartphones</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99659071165">Xiaochen Liu</a>,
<a href="author_page.cfm?id=81100660706">Suman Nath</a>,
<a href="author_page.cfm?id=81327488641">Ramesh Govindan</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 163-177</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210343" title="DOI">10.1145/3210240.3210343</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210343&amp;ftid=1984496&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Other formats:
<a name="OtherFormatswebm" title="Other Formats webm" href="ft_gateway.cfm?id=3210343&amp;ftid=1992735&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/webm.jpg" alt="webm" class="fulltext_lnk" border="0">webm</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow13" style="display:inline;"><br><div style="display:inline">Accurate positioning in urban areas is important for personal navigation, geolocation apps, and ride-sharing. Smartphones localize themselves using GPS position estimates, and augment these with a variety of techniques including dead reckoning, map matching, ...</div></span>
<span id="toHide13" style="display:none;"><br><div style="display:inline"><p>Accurate positioning in urban areas is important for personal navigation, geolocation apps, and ride-sharing. Smartphones localize themselves using GPS position estimates, and augment these with a variety of techniques including dead reckoning, map matching, and WiFi localization. However, GPS signals suffer significant impairment in urban canyons because of limited line-of-sight to satellites and signal reflections. In this paper, we focus on scalable and deployable techniques to reduce the impact of one specific impairment: reflected GPS signals from non-line-of-sight (NLOS) satellites. Specifically, we show how, using publicly available street-level imagery and off-the-shelf computer vision techniques, we can estimate the path inflation incurred by (the extra distance traveled by) a reflected signal from a satellite. Using these path inflation estimates we develop techniques to estimate the most likely actual position given a set of satellite readings at some position. Finally, we develop optimizations for fast position estimation on modern smartphones. Using extensive experiments in the downtown area of several large cities, we find that our techniques can reduce positioning error by up to 55% on average.</p></div></span> <a id="expcoll13" href="JavaScript: expandcollapse('expcoll13',13)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210318">Explicit Channel Coordination via Cross-technology Communication</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99658672071">Zhimeng Yin</a>,
<a href="author_page.cfm?id=99659209451">Zhijun Li</a>,
<a href="author_page.cfm?id=99659240940">Song Min Kim</a>,
<a href="author_page.cfm?id=99659207764">Tian He</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 178-190</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210318" title="DOI">10.1145/3210240.3210318</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210318&amp;ftid=1984458&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Other formats:
<a name="OtherFormatswebm" title="Other Formats webm" href="ft_gateway.cfm?id=3210318&amp;ftid=1992736&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/webm.jpg" alt="webm" class="fulltext_lnk" border="0">webm</a>
</span>
</td>
</tr>

<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow14" style="display:inline;"><br><div style="display:inline">Under significant coexistence in the ISM band, the impact of cross-technology interference (CTI) has become a major threat to low-power IoT. This paper presents ECC that uniquely enables explicit channel coordination among heterogeneities via cross-technology ...</div></span>
<span id="toHide14" style="display:none;"><br><div style="display:inline"><p>Under significant coexistence in the ISM band, the impact of cross-technology interference (CTI) has become a major threat to low-power IoT. This paper presents ECC that uniquely enables explicit channel coordination among heterogeneities via cross-technology communication (CTC) introduced in the latest studies, while maintaining full compatibility to commodity devices. Unlike any implicit coordination designs adopting statistical models to probabilistically predict white spaces, ECC generates the white space using WiFi CTS, which is then explicitly notified to ZigBee through CTC for immediate use. Technical highlight of ECC lies in ensuring ZigBee communication under CTI, without disrupting WiFi operation. This is effectively achieved by the dynamic adjustment of CTS duration with respect to traffic amount and spectrum availability, which essentially enables ECC to be generally applied to various scenarios without prior knowledge. Lastly, ECC significantly reduces delay and energy in low duty cycled ZigBee, by waking them up upon channel availability (via CTC). We evaluate ECC on commercial platforms: Atheros AR2425 WiFi card and TelosB motes. Experiment results show that ECC achieves 1.8x ZigBee packet reception ratio, and cuts down delay and energy by 98.6% and 51% under the low duty cycle.</p></div></span> <a id="expcoll14" href="JavaScript: expandcollapse('expcoll14',14)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210329">Spatial Stream Backscatter Using Commodity WiFi</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99659282614">Jia Zhao</a>,
<a href="author_page.cfm?id=99659254012">Wei Gong</a>,
<a href="author_page.cfm?id=99659202923">Jiangchuan Liu</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 191-203</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210329" title="DOI">10.1145/3210240.3210329</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210329&amp;ftid=1984450&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Other formats:
<a name="OtherFormatswebm" title="Other Formats webm" href="ft_gateway.cfm?id=3210329&amp;ftid=1992746&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/webm.jpg" alt="webm" class="fulltext_lnk" border="0">webm</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow15" style="display:inline;"><br><div style="display:inline">Backscatter WiFi offers a novel low-cost and low-energy solution for RFID tags to communicate with existing WiFi devices. State-of-the-art backscatter WiFi solutions have seldom explored advanced features in the latest WiFi standards, in particular, ...</div></span>
<span id="toHide15" style="display:none;"><br><div style="display:inline"><p>Backscatter WiFi offers a novel low-cost and low-energy solution for RFID tags to communicate with existing WiFi devices. State-of-the-art backscatter WiFi solutions have seldom explored advanced features in the latest WiFi standards, in particular, spatial multiplexing, which has been the cornerstone for 802.11n and beyond. In this paper, we present MOXcatter, a WiFi backscatter communication system that works with spatial streams using commodity radios, while keeping the ongoing data communication unaffected. In MOXcatter, a backscatter tag can embed its sensing data on ambient spatial-stream packets, and both the sensing data and the original packets can be decoded by commodity WiFi devices. We have built a MOXcatter prototype with FPGAs and commodity WiFi devices. The experiments show that MOXcatter achieves up to 50 Kbps throughput for a single stream and up to 1 Kbps for double streams with a communication range (tag-to-RX) up to 14 m. We discuss the tradeoffs therein and possible enhancements, and also showcase the applicability of our design through a sensor communication system.</p></div></span> <a id="expcoll15" href="JavaScript: expandcollapse('expcoll15',15)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210346">Chiron: Concurrent High Throughput Communication for IoT Devices</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99659284962">Yan Li</a>,
<a href="author_page.cfm?id=99659085971">Zicheng Chi</a>,
<a href="author_page.cfm?id=99659207235">Xin Liu</a>,
<a href="author_page.cfm?id=99659283959">Ting Zhu</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 204-216</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210346" title="DOI">10.1145/3210240.3210346</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210346&amp;ftid=1984437&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Other formats:
<a name="OtherFormatswebm" title="Other Formats webm" href="ft_gateway.cfm?id=3210346&amp;ftid=1992726&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/webm.jpg" alt="webm" class="fulltext_lnk" border="0">webm</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow16" style="display:inline;"><br><div style="display:inline">The exponentially increasing number of heterogeneous Internet of Things (IoT) devices motivate us to explore more efficient and higher throughput communication, especially at the bottleneck (i.e., edge) of the IoT networks. Our work, named Chiron, opens ...</div></span>
<span id="toHide16" style="display:none;"><br><div style="display:inline"><p>The exponentially increasing number of heterogeneous Internet of Things (IoT) devices motivate us to explore more efficient and higher throughput communication, especially at the bottleneck (i.e., edge) of the IoT networks. Our work, named Chiron, opens a promising direction for Physical (PHY) layer concurrent high throughput communication to heterogeneous IoT devices (e.g., wider-band WiFi and narrower-band ZigBee). Specifically, at the PHY layer, Chiron enables concurrently transmitting (or receiving) 1 stream of WiFi data and up to 4 streams of ZigBee data to (or from) commodity WiFi and ZigBee devices as if there is no interference between these simultaneous connections. We extensively evaluate our system under different real-world settings. Results show that Chiron's concurrent WiFi and ZigBee communication can achieve similar throughput as the sole WiFi or ZigBee communication. Chiron's spectrum utilization is more than 16 times better than the traditional gateway.</p></div></span> <a id="expcoll16" href="JavaScript: expandcollapse('expcoll16',16)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210341">CoReCast: Collision Resilient Broadcasting in Vehicular Networks</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99659075144">Tanmoy Das</a>,
<a href="author_page.cfm?id=99659074553">Lu Chen</a>,
<a href="author_page.cfm?id=99659081847">Rupam Kundu</a>,
<a href="author_page.cfm?id=99659283123">Arjun Bakshi</a>,
<a href="author_page.cfm?id=81332527996">Prasun Sinha</a>,
<a href="author_page.cfm?id=81502650216">Kannan Srinivasan</a>,
<a href="author_page.cfm?id=99659132433">Gaurav Bansal</a>,
<a href="author_page.cfm?id=99659284572">Takayuki Shimizu</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 217-229</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210341" title="DOI">10.1145/3210240.3210341</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210341&amp;ftid=1984508&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Other formats:
<a name="OtherFormatswebm" title="Other Formats webm" href="ft_gateway.cfm?id=3210341&amp;ftid=1992727&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/webm.jpg" alt="webm" class="fulltext_lnk" border="0">webm</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow17" style="display:inline;"><br><div style="display:inline">Reliable and timely delivery of periodic V2V (vehicle-to-vehicle) broadcast messages is essential for realizing the benefits of connected vehicles. Existing MAC protocols for ad hoc networks fall short of meeting these requirements. In this paper, we ...</div></span>
<span id="toHide17" style="display:none;"><br><div style="display:inline"><p>Reliable and timely delivery of periodic V2V (vehicle-to-vehicle) broadcast messages is essential for realizing the benefits of connected vehicles. Existing MAC protocols for ad hoc networks fall short of meeting these requirements. In this paper, we present, CoReCast, the first collision embracing protocol for vehicular networks. CoReCast provides high reliability and low delay by leveraging two unique opportunities: no strict constraint on energy consumption, and availability of GPS clocks to achieve near-perfect time and frequency synchronization.</p> <p>Due to low coherence time, the channel changes rapidly in vehicular networks. CoReCast embraces packet collisions and takes advantage of the channel dynamics to decode collided packets. The design of CoReCast is based on a preamble detection scheme that estimates channels from multiple transmitters without any prior information about them. The proposed scheme reduces the space and time requirement exponentially than the existing schemes. The system is evaluated through experiments with USRP N210 and GPS devices placed in vehicles driven on roads in different environments as well as using trace-driven simulations. It provides 15x and 2x lower delay than 802.11p and OCP (Omniscient Clustering Protocol), respectively. Reliability of CoReCast is 8x and 2x better than 802.11p and OCP, respectively.</p></div></span> <a id="expcoll17" href="JavaScript: expandcollapse('expcoll17',17)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210321">SandTrap: Tracking Information Flows On Demand with Parallel Permissions</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=81466648034">Ali Razeen</a>,
<a href="author_page.cfm?id=81100265767">Alvin R. Lebeck</a>,
<a href="author_page.cfm?id=99659283882">David H. Liu</a>,
<a href="author_page.cfm?id=99658983413">Alexander Meijer</a>,
<a href="author_page.cfm?id=82259142057">Valentin Pistol</a>,
<a href="author_page.cfm?id=81100290542">Landon P. Cox</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 230-242</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210321" title="DOI">10.1145/3210240.3210321</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210321&amp;ftid=1984469&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Other formats:
<a name="OtherFormatswebm" title="Other Formats webm" href="ft_gateway.cfm?id=3210321&amp;ftid=1992747&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/webm.jpg" alt="webm" class="fulltext_lnk" border="0">webm</a>
</span>
</td>
</tr>
 <tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow18" style="display:inline;"><br><div style="display:inline">The most promising way to improve the performance of dynamic information-flow tracking (DIFT) for machine code is to only track instructions when they process tainted data. Unfortunately, prior approaches to on-demand DIFT are a poor match for modern ...</div></span>
<span id="toHide18" style="display:none;"><br><div style="display:inline"><p>The most promising way to improve the performance of dynamic information-flow tracking (DIFT) for machine code is to only track instructions when they process tainted data. Unfortunately, prior approaches to on-demand DIFT are a poor match for modern mobile platforms that rely heavily on parallelism to provide good interactivity in the face of computationally intensive tasks like image processing. The main shortcoming of these prior efforts is that they cannot support an arbitrary mix of parallel threads due to the limitations of page protections.</p> <p>In this paper, we identify parallel permissions as a key requirement for multithreaded, on-demand native DIFT, and we describe the design and implementation of a system called SandTrap that embodies this approach. Using our prototype implementation, we demonstrate that SandTrap's native DIFT overhead is proportional to the amount of tainted data that native code processes. For example, in the photo-sharing app Instagram, SandTrap's performance is close to baseline (1x) when the app does not access tainted data. When it does, SandTrap imposes a slowdown comparable to prior DIFT systems (~8x).</p></div></span> <a id="expcoll18" href="JavaScript: expandcollapse('expcoll18',18)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210332">Detecting Wireless Spy Cameras Via Stimulating and Probing</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99659284032">Tian Liu</a>,
<a href="author_page.cfm?id=99659283972">Ziyu Liu</a>,
<a href="author_page.cfm?id=99659283048">Jun Huang</a>,
<a href="author_page.cfm?id=99659283924">Rui Tan</a>,
<a href="author_page.cfm?id=99659283443">Zhen Tan</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 243-255</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210332" title="DOI">10.1145/3210240.3210332</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210332&amp;ftid=1984502&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Other formats:
<a name="OtherFormatswebm" title="Other Formats webm" href="ft_gateway.cfm?id=3210332&amp;ftid=1992728&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/webm.jpg" alt="webm" class="fulltext_lnk" border="0">webm</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
 <div style="padding-left:0">
<span id="toShow19" style="display:inline;"><br><div style="display:inline">The rapid proliferation of wireless video cameras has raised serious privacy concerns. In this paper, we propose a stimulating-and-probing approach to detecting wireless spy cameras. The core idea is to actively alter the light condition of a private ...</div></span>
<span id="toHide19" style="display:none;"><br><div style="display:inline"><p>The rapid proliferation of wireless video cameras has raised serious privacy concerns. In this paper, we propose a stimulating-and-probing approach to detecting wireless spy cameras. The core idea is to actively alter the light condition of a private space to manipulate the spy camera's video scene, and then investigates the responsive variations of a packet flow to determine if it is produced by a wireless camera. Following this approach, we develop Blink and Flicker -- two practical systems for detecting wireless spy cameras. Blink is a lightweight app that can be deployed on off-the-shelf mobile devices. It asks the user to turn on/off the light of her private space, and then uses the light sensor and the wireless radio of the mobile device to identify the response of wireless cameras. Flicker is a robust and automated system that augments Blink to detect wireless cameras in both live and offline streaming modes. Flicker employs a cheap and portable circuit, which harnesses daily used LEDs to stimulate wireless cameras using human-invisible flickering. The time series of stimuli is further encoded using FEC to combat ambient light and uncontrollable packet flow variations that may degrade detection performance. Extensive experiments show that Blink and Flicker can accurately detect wireless cameras under a wide range of network and environmental conditions.</p></div></span> <a id="expcoll19" href="JavaScript: expandcollapse('expcoll19',19)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210333">Shadow Wi-Fi: Teaching Smartphones to Transmit Raw Signals and to Extract Channel State Information to Implement Practical Covert Channels over Wi-Fi</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99658620553">Matthias Schulz</a>,
<a href="author_page.cfm?id=99659282767">Jakob Link</a>,
<a href="author_page.cfm?id=81322494421">Francesco Gringoli</a>,
<a href="author_page.cfm?id=81100325093">Matthias Hollick</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 256-268</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210333" title="DOI">10.1145/3210240.3210333</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210333&amp;ftid=1984459&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Other formats:
<a name="OtherFormatswebm" title="Other Formats webm" href="ft_gateway.cfm?id=3210333&amp;ftid=1992748&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/webm.jpg" alt="webm" class="fulltext_lnk" border="0">webm</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow20" style="display:inline;"><br><div style="display:inline">Wi-Fi chips offer vast capabilities, which are not accessible through the manufacturers' official firmwares. Unleashing those capabilities can enable innovative applications on off-the-shelf devices. In this work, we demonstrate how to transmit raw IQ ...</div></span>
<span id="toHide20" style="display:none;"><br><div style="display:inline"><p>Wi-Fi chips offer vast capabilities, which are not accessible through the manufacturers' official firmwares. Unleashing those capabilities can enable innovative applications on off-the-shelf devices. In this work, we demonstrate how to transmit raw IQ samples from a large buffer on Wi-Fi chips. We further show how to extract channel state information (CSI) on a per frame basis. As a proof-of-concept application, we build a covert channel on top of Wi-Fi to stealthily exchange information between two devices by prefiltering Wi-Fi frames prior to transmission. On the receiver side, the CSI is used to extract the embedded information. By means of experimentation, we show that regular Wi-Fi clients can still demodulate the underlying Wi-Fi frames. Our results show that covert channels on the physical layer are practical and run on off-the-shelf smartphones. By making available our raw signal transmitter, the CSI extractor, and the covert channel application to the research community, we ensure reproducibility and offer a platform for further innovative applications on Wi-Fi devices.</p></div></span> <a id="expcoll20" href="JavaScript: expandcollapse('expcoll20',20)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210322">TYTH-Typing On Your Teeth: Tongue-Teeth Localization for Human-Computer Interface</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99658736206">Phuc Nguyen</a>,
<a href="author_page.cfm?id=99659180793">Nam Bui</a>,
<a href="author_page.cfm?id=99659045908">Anh Nguyen</a>,
<a href="author_page.cfm?id=99659180691">Hoang Truong</a>,
<a href="author_page.cfm?id=99659284387">Abhijit Suresh</a>,
<a href="author_page.cfm?id=99659200673">Matt Whitlock</a>,
<a href="author_page.cfm?id=84758701357">Duy Pham</a>,
<a href="author_page.cfm?id=81442596640">Thang Dinh</a>,
<a href="author_page.cfm?id=99659181026">Tam Vu</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 269-282</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210322" title="DOI">10.1145/3210240.3210322</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210322&amp;ftid=1984438&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow21" style="display:inline;"><br><div style="display:inline">This paper explores a new wearable system, called TYTH, that enables a novel form of human computer interaction based on the relative location and interaction between the user's tongue and teeth. TYTH allows its user to interact with a computing system ...</div></span>
<span id="toHide21" style="display:none;"><br><div style="display:inline"><p>This paper explores a new wearable system, called TYTH, that enables a novel form of human computer interaction based on the relative location and interaction between the user's tongue and teeth. TYTH allows its user to interact with a computing system by tapping on their teeth. This form of interaction is analogous to using a finger to type on a keypad except that the tongue substitutes for the finger and the teeth for the keyboard. We study the neurological and anatomical structures of the tongue to design TYTH so that the obtrusiveness and social awkwardness caused by the wearable is minimized while maximizing its accuracy and sensing sensitivity. From behind the user's ears, TYTH senses the brain signals and muscle signals that control tongue movement sent from the brain and captures the miniature skin surface deformation caused by tongue movement. We model the relationship between tongue movement and the signals recorded, from which a tongue localization technique and tongue-teeth tapping detection technique are derived. Through a prototyping implementation and an evaluation with 15 subjects, we show that TYTH can be used as a form of hands-free human computer interaction with 88.61% detection rate and promising adoption rate by users.</p></div></span> <a id="expcoll21" href="JavaScript: expandcollapse('expcoll21',21)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210315">Depth Aware Finger Tapping on Virtual Displays</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99659075146">Ke Sun</a>,
<a href="author_page.cfm?id=99658741517">Wei Wang</a>,
<a href="author_page.cfm?id=99659282637">Alex X. Liu</a>,
<a href="author_page.cfm?id=84459008857">Haipeng Dai</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 283-295</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210315" title="DOI">10.1145/3210240.3210315</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210315&amp;ftid=1984470&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Other formats:
<a name="OtherFormatswebm" title="Other Formats webm" href="ft_gateway.cfm?id=3210315&amp;ftid=1992737&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/webm.jpg" alt="webm" class="fulltext_lnk" border="0">webm</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow22" style="display:inline;"><br><div style="display:inline">For AR/VR systems, tapping-in-the-air is a user-friendly solution for interactions. Most prior in-air tapping schemes use customized depth-cameras and therefore have the limitations of low accuracy and high latency. In this paper, we propose a fine-grained ...</div></span>
<span id="toHide22" style="display:none;"><br><div style="display:inline"><p>For AR/VR systems, tapping-in-the-air is a user-friendly solution for interactions. Most prior in-air tapping schemes use customized depth-cameras and therefore have the limitations of low accuracy and high latency. In this paper, we propose a fine-grained depth-aware tapping scheme that can provide high accuracy tapping detection. Our basic idea is to use light-weight ultrasound based sensing, along with one COTS mono-camera, to enable 3D tracking of user's fingers. The mono-camera is used to track user's fingers in the 2D space and ultrasound based sensing is used to get the depth information of user's fingers in the 3D space. Using speakers and microphones that already exist on most AR/VR devices, we emit ultrasound, which is inaudible to humans, and capture the signal reflected by the finger with the microphone. From the phase changes of the ultrasound signal, we accurately measure small finger movements in the depth direction. With fast and light-weight ultrasound signal processing algorithms, our scheme can accurately track finger movements and measure the bending angle of the finger between two video frames. In our experiments on eight users, our scheme achieves a 98.4% finger tapping detection accuracy with FPR of 1.6% and FNR of 1.4%, and a detection latency of 17.69ms, which is 57.7ms less than video-only schemes. The power consumption overhead of our scheme is 48.4% more than video-only schemes.</p></div></span> <a id="expcoll22" href="JavaScript: expandcollapse('expcoll22',22)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210344">Brain Password: A Secure and Truly Cancelable Brain Biometrics for Smart Headwear</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99658723698">Feng Lin</a>,
<a href="author_page.cfm?id=99659283560">Kun Woo Cho</a>,
<a href="author_page.cfm?id=99658715084">Chen Song</a>,
<a href="author_page.cfm?id=84459579257">Wenyao Xu</a>,
<a href="author_page.cfm?id=84459017657">Zhanpeng Jin</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 296-309</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210344" title="DOI">10.1145/3210240.3210344</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210344&amp;ftid=1984486&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Other formats:
<a name="OtherFormatswebm" title="Other Formats webm" href="ft_gateway.cfm?id=3210344&amp;ftid=1992738&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/webm.jpg" alt="webm" class="fulltext_lnk" border="0">webm</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow23" style="display:inline;"><br><div style="display:inline">In recent years, biometric techniques (e.g., fingerprint or iris) are increasingly integrated into mobile devices to offer security advantages over traditional practices (e.g., passwords and PINs) due to their ease of use in user authentication. However, ...</div></span>
<span id="toHide23" style="display:none;"><br><div style="display:inline"><p>In recent years, biometric techniques (e.g., fingerprint or iris) are increasingly integrated into mobile devices to offer security advantages over traditional practices (e.g., passwords and PINs) due to their ease of use in user authentication. However, existing biometric systems are with controversy: once divulged, they are compromised forever - no one can grow a new fingerprint or iris. This work explores a truly cancelable brain-based biometric system for mobile platforms (e.g., smart headwear). Specifically, we present a new psychophysiological protocol via non-volitional brain response for trustworthy mobile authentication, with an application example of smart headwear. Particularly, we address the following research challenges in mobile biometrics with a theoretical and empirical combined manner: (1) how to generate reliable brain responses with sophisticated visual stimuli; (2) how to acquire the distinct brain response and analyze unique features in the mobile platform; (3) how to reset and change brain biometrics when the current biometric credential is divulged. To evaluate the proposed solution, we conducted a pilot study and achieved an f -score accuracy of 95.46% and equal error rate (EER) of 2.503%, thereby demonstrating the potential feasibility of neurofeedback based biometrics for smart headwear. Furthermore, we perform the cancelability study and the longitudinal study, respectively, to show the effectiveness and usability of our new proposed mobile biometric system. To the best of our knowledge, it is the first in-depth research study on truly cancelable brain biometrics for secure mobile authentication.</p></div></span> <a id="expcoll23" href="JavaScript: expandcollapse('expcoll23',23)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210326">MicroMobile: Leveraging Mobile Advertising for Large-Scale Experimentation</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=81410595346">Mark D. Corner</a>,
<a href="author_page.cfm?id=81100230239">Brian N. Levine</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 310-322</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210326" title="DOI">10.1145/3210240.3210326</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210326&amp;ftid=1984439&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Other formats:
<a name="OtherFormatswebm" title="Other Formats webm" href="ft_gateway.cfm?id=3210326&amp;ftid=1992739&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/webm.jpg" alt="webm" class="fulltext_lnk" border="0">webm</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow24" style="display:inline;"><br><div style="display:inline">Mobile systems researchers struggle with conducting experiments with real users: either the scale of the study lacks sufficient scale and diversity, or a great effort must be used to recruit and manage subjects. In this paper, we describe MicroMobile, ...</div></span>
<span id="toHide24" style="display:none;"><br><div style="display:inline"><p>Mobile systems researchers struggle with conducting experiments with real users: either the scale of the study lacks sufficient scale and diversity, or a great effort must be used to recruit and manage subjects. In this paper, we describe MicroMobile, a system for deploying short data-gathering experiments to an extremely diverse set of users via mobile advertising. We conduct experiments in three mediums: interactive advertisements, mobile browsers, and native applications on both major mobile operating systems.</p> <p>We use MicroMobile to demonstrate how researchers can use mobile advertising to recruit users, for as little as $1.50 per completed experiment. Across almost 500 completed experiments, we found that interactive ads have the highest participation rate (and thus lowest cost), which was 2x the participation rate of browser experiments and more than 6x native app experiments. Users were also highly diverse, spanning age, income, and ethnicity. While native apps are the most powerful platform, they constitute the most expensive targets. However, as mobile browsers add sensor APIs, browser-based experimentation has increasing applicability.</p></div></span> <a id="expcoll24" href="JavaScript: expandcollapse('expcoll24',24)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210342">TAR: Enabling Fine-Grained Targeted Advertising in Retail Stores</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99659284134">Xiaochen Liu</a>,
<a href="author_page.cfm?id=99659225809">Yurong Jiang</a>,
<a href="author_page.cfm?id=99659074665">Puneet Jain</a>,
<a href="author_page.cfm?id=99659226969">Kyu-Han Kim</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 323-336</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210342" title="DOI">10.1145/3210240.3210342</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210342&amp;ftid=1984503&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Other formats:
<a name="OtherFormatswebm" title="Other Formats webm" href="ft_gateway.cfm?id=3210342&amp;ftid=1992752&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/webm.jpg" alt="webm" class="fulltext_lnk" border="0">webm</a>
</span>
</td> 
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow25" style="display:inline;"><br><div style="display:inline">Mobile advertisements influence customers' in-store purchases and boost in-store sales for brick-and-mortar retailers. Targeting mobile ads has become significantly important to compete with online shopping. The key to enabling targeted mobile advertisement ...</div></span>
<span id="toHide25" style="display:none;"><br><div style="display:inline"><p>Mobile advertisements influence customers' in-store purchases and boost in-store sales for brick-and-mortar retailers. Targeting mobile ads has become significantly important to compete with online shopping. The key to enabling targeted mobile advertisement and service is to learn shoppers' interest during their stay in the store. Precise shopper tracking and identification are essential to gain the insights. However, existing sensor-based or vision-based solutions are neither practical nor accurate; no commercial solutions today can be readily deployed in a large store. On the other hand, we recognize that most retail stores have the installation of surveillance cameras, and most shoppers carry Bluetooth-enabled smartphones. Thus, in this paper, we propose TAR to learn shoppers' in-store interest via accurate multi-camera people tracking and identification. TAR leverages widespread camera deployment and Bluetooth proximity information to accurately track and identify shoppers in the store. TAR is composed of four novel design components: (1) a deep neural network (DNN) based visual tracking, (2) a user trajectory estimation by using shopper visual and BLE proximity trace, (3) an identity matching and assignment to recognize shopper's identity, and (4) a cross-camera calibration algorithm. TAR carefully combines these components to track and identify shoppers in real-time. TAR achieves 90% accuracy in two different real-life deployments, which is 20% better than the state-of-the-art solution.</p></div></span> <a id="expcoll25" href="JavaScript: expandcollapse('expcoll25',25)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210320">CrowdEstimator: Approximating Crowd Sizes with Multi-modal Data for Internet-of-Things Services</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99659284125">Fang-Jing Wu</a>,
<a href="author_page.cfm?id=81558091356">G√ºrkan Solmaz</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 337-349</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210320" title="DOI">10.1145/3210240.3210320</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210320&amp;ftid=1984460&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Other formats:
<a name="OtherFormatswebm" title="Other Formats webm" href="ft_gateway.cfm?id=3210320&amp;ftid=1992729&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/webm.jpg" alt="webm" class="fulltext_lnk" border="0">webm</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow26" style="display:inline;"><br><div style="display:inline">Crowd mobility has been paid attention for the Internet-of-things (IoT) applications. This paper addresses the crowd estimation problem and builds an IoT service to share the crowd estimation results across different systems. The crowd estimation problem ...</div></span>
<span id="toHide26" style="display:none;"><br><div style="display:inline"><p>Crowd mobility has been paid attention for the Internet-of-things (IoT) applications. This paper addresses the crowd estimation problem and builds an IoT service to share the crowd estimation results across different systems. The crowd estimation problem is to approximate the crowd size in a targeted area using the observed information (e.g., Wi-Fi data). This paper exploits Wi-Fi probe request packets ("Wi-Fi probes" for short) broadcasted by mobile devices to solve this problem. However, using only Wi-Fi probes to estimate the crowd size may result in inaccurate results due to various environmental uncertainties which may lead to crowd overestimation or underestimation. Moreover, the ground-truth is unavailable because the coverage of Wi-Fi signals is time-varying and invisible. This paper introduces auxiliary sensors, stereoscopic cameras, to collect the near ground-truth at a specified calibration choke point. Two calibration algorithms are proposed to solve the crowd estimation problem. The key idea is to calibrate the Wi-Fi-only crowd estimation based on the correlations between the two types of data modalities. Then, to share the calibrated results across systems required by different stakeholders, our system is integrated with the FIWARE-based IoT platform. To verify the proposed system, we have launched an indoor pilot study in the Wellington Railway Station and an outdoor pilot study in the Christchurch Re:START Mall in New Zealand. The large-scale pilot studies show that stereoscopic cameras can reach minimum accuracy of 85% and high precision detection for providing the near ground-truth. The proposed calibration algorithms reduce estimation errors by 43.68% on average compared to the Wi-Fi-only approach.</p></div></span> <a id="expcoll26" href="JavaScript: expandcollapse('expcoll26',26)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210314">Widar2.0: Passive Human Tracking with a Single Wi-Fi Link</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99659075335">Kun Qian</a>,
<a href="author_page.cfm?id=84458770257">Chenshu Wu</a>,
<a href="author_page.cfm?id=99659284651">Yi Zhang</a>,
<a href="author_page.cfm?id=99659284114">Guidong Zhang</a>,
<a href="author_page.cfm?id=86158681457">Zheng Yang</a>,
<a href="author_page.cfm?id=81371594524">Yunhao Liu</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 350-361</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210314" title="DOI">10.1145/3210240.3210314</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210314&amp;ftid=1984471&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Other formats:
<a name="OtherFormatswebm" title="Other Formats webm" href="ft_gateway.cfm?id=3210314&amp;ftid=1992757&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/webm.jpg" alt="webm" class="fulltext_lnk" border="0">webm</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow27" style="display:inline;"><br><div style="display:inline">This paper presents Widar2.0, the first WiFi-based system that enables passive human localization and tracking using a single link on commodity off-the-shelf devices. Previous works based on either specialized or commercial hardware all require multiple ...</div></span>
<span id="toHide27" style="display:none;"><br><div style="display:inline"><p>This paper presents Widar2.0, the first WiFi-based system that enables passive human localization and tracking using a single link on commodity off-the-shelf devices. Previous works based on either specialized or commercial hardware all require multiple links, preventing their wide adoption in scenarios like homes where typically only one single AP is installed. The key insight underlying Widar2.0 to circumvent the use of multiple links is to leverage multi-dimensional signal parameters from one single link. To this end, we build a unified model accounting for Angle-of-Arrival, Time-of-Flight, and Doppler shifts together and devise an efficient algorithm for their joint estimation. We then design a pipeline to translate the erroneous raw parameters into precise locations, which first finds parameters corresponding to the reflections of interests, then refines range estimates, and ultimately outputs target locations. Our implementation and evaluation on commodity WiFi devices demonstrate that Widar2.0 achieves better or comparable performance to state-of-the-art localization systems, which either use specialized hardwares or require 2 to 40 Wi-Fi links.</p></div></span> <a id="expcoll27" href="JavaScript: expandcollapse('expcoll27',27)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210340">Augmenting Indoor Inertial Tracking with Polarized Light</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99658740527">Zhao Tian</a>,
<a href="author_page.cfm?id=99658720639">Yu-Lin Wei</a>,
<a href="author_page.cfm?id=99659207830">Wei-Nin Chang</a>,
<a href="author_page.cfm?id=99659075211">Xi Xiong</a>,
<a href="author_page.cfm?id=99659208507">Changxi Zheng</a>,
<a href="author_page.cfm?id=82158644057">Hsin-Mu Tsai</a>,
<a href="author_page.cfm?id=84458958357">Kate Ching-Ju Lin</a>,
<a href="author_page.cfm?id=99659074824">Xia Zhou</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 362-375</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210340" title="DOI">10.1145/3210240.3210340</a></span></td>
</tr>
<tr>
<td></td>
 <td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210340&amp;ftid=1984440&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Other formats:
<a name="OtherFormatswebm" title="Other Formats webm" href="ft_gateway.cfm?id=3210340&amp;ftid=1992730&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/webm.jpg" alt="webm" class="fulltext_lnk" border="0">webm</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow28" style="display:inline;"><br><div style="display:inline">Inertial measurement unit (IMU) has long suffered from the problem of integration drift, where sensor noises accumulate quickly and cause fast-growing tracking errors. Existing methods for calibrating IMU tracking either require human in the loop, or ...</div></span>
<span id="toHide28" style="display:none;"><br><div style="display:inline"><p>Inertial measurement unit (IMU) has long suffered from the problem of integration drift, where sensor noises accumulate quickly and cause fast-growing tracking errors. Existing methods for calibrating IMU tracking either require human in the loop, or need energy-consuming cameras, or suffer from coarse tracking granularity. We propose to augment indoor inertial tracking by reusing existing indoor luminaries to project a static light polarization pattern in the space. This pattern is imperceptible to human eyes and yet through a polarizer, it becomes detectable by a color sensor, and thus can serve as fine-grained optical landmarks that constrain and correct IMU's integration drift and boost tracking accuracy. Exploiting the birefringence optical property of transparent tapes -- a low-cost and easily-accessible material -- we realize the polarization pattern by simply adding to existing light cover a thin polarizer film with transparent tape stripes glued atop. When fusing with IMU sensor signals, the light pattern enables robust, accurate and low-power motion tracking. Meanwhile, our approach entails low deployment overhead by reusing existing lighting infrastructure without needing an active modulation unit. We build a prototype of our light cover and the sensing unit using off-the-shelf components. Experiments show 4.3 cm median error for 2D tracking and 10 cm for 3D tracking, as well as its robustness in diverse settings.</p></div></span> <a id="expcoll28" href="JavaScript: expandcollapse('expcoll28',28)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210347">Multipath Triangulation: Decimeter-level WiFi Localization and Orientation with a Single Unaided Receiver</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99659084334">Elahe Soltanaghaei</a>,
<a href="author_page.cfm?id=99658750877">Avinash Kalyanaraman</a>,
<a href="author_page.cfm?id=81100551318">Kamin Whitehouse</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 376-388</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210347" title="DOI">10.1145/3210240.3210347</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210347&amp;ftid=1984504&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Other formats:
<a name="OtherFormatswebm" title="Other Formats webm" href="ft_gateway.cfm?id=3210347&amp;ftid=1992740&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/webm.jpg" alt="webm" class="fulltext_lnk" border="0">webm</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow29" style="display:inline;"><br><div style="display:inline">Decimeter-level localization has become a reality, in part due to the ability to eliminate the effects of multipath interference. In this paper, we demonstrate the ability to use multipath reflections to enhance localization rather than throwing them ...</div></span>
<span id="toHide29" style="display:none;"><br><div style="display:inline"><p>Decimeter-level localization has become a reality, in part due to the ability to eliminate the effects of multipath interference. In this paper, we demonstrate the ability to use multipath reflections to enhance localization rather than throwing them away. We present Multipath Triangulation, a new localization technique that uses multipath reflections to localize a target device with a single receiver that does not require any form of coordination with any other devices. In this paper, we leverage multipath triangulation to build the first decimeter-level WiFi localization system, called MonoLoco, that requires only a single access point (AP) and a single channel, and does not impose any overhead, data sharing, or coordination protocols beyond standard WiFi communication. As a bonus, it also determines the orientation of the target relative to the AP. We implemented MonoLoco using Intel 5300 commodity WiFi cards and deploy it in four environments with different multipath propagation. Results indicate median localization error of 0.5m and median orientation error of 6.6 degrees, which are comparable to the best performing prior systems, all of which require multiple APs and/or multiple frequency channels. High accuracy can be achieved with only a handful of packets.</p></div></span> <a id="expcoll29" href="JavaScript: expandcollapse('expcoll29',29)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210337">On-Demand Deep Model Compression for Mobile Devices: A Usage-Driven Model Selection Framework</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99659282954">Sicong Liu</a>,
<a href="author_page.cfm?id=99659282484">Yingyan Lin</a>,
<a href="author_page.cfm?id=99659282936">Zimu Zhou</a>,
<a href="author_page.cfm?id=99659282381">Kaiming Nan</a>,
<a href="author_page.cfm?id=99659057547">Hui Liu</a>,
<a href="author_page.cfm?id=99659284461">Junzhao Du</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 389-400</span></td>
 </tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210337" title="DOI">10.1145/3210240.3210337</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210337&amp;ftid=1984461&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Other formats:
<a name="OtherFormatswebm" title="Other Formats webm" href="ft_gateway.cfm?id=3210337&amp;ftid=1992753&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/webm.jpg" alt="webm" class="fulltext_lnk" border="0">webm</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow30" style="display:inline;"><br><div style="display:inline">Recent research has demonstrated the potential of deploying deep neural networks (DNNs) on resource-constrained mobile platforms by trimming down the network complexity using different compression techniques. The current practice only investigate stand-alone ...</div></span>
<span id="toHide30" style="display:none;"><br><div style="display:inline"><p>Recent research has demonstrated the potential of deploying deep neural networks (DNNs) on resource-constrained mobile platforms by trimming down the network complexity using different compression techniques. The current practice only investigate stand-alone compression schemes even though each compression technique may be well suited only for certain types of DNN layers. Also, these compression techniques are optimized merely for the inference accuracy of DNNs, without explicitly considering other application-driven system performance (e.g. latency and energy cost) and the varying resource availabilities across platforms (e.g. storage and processing capability). In this paper, we explore the desirable tradeoff between performance and resource constraints by user-specified needs, from a holistic system-level viewpoint. Specifically, we develop a usage-driven selection framework, referred to as AdaDeep, to automatically select a combination of compression techniques for a given DNN, that will lead to an optimal balance between user-specified performance goals and resource constraints. With an extensive evaluation on five public datasets and across twelve mobile devices, experimental results show that AdaDeep enables up to 9.8x latency reduction, 4.3x energy efficiency improvement, and 38x storage reduction in DNNs while incurring negligible accuracy loss. AdaDeep also uncovers multiple effective combinations of compression techniques unexplored in existing literature.</p></div></span> <a id="expcoll30" href="JavaScript: expandcollapse('expcoll30',30)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210335">Multi-User Gesture Recognition Using WiFi</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99659254349">Raghav H. Venkatnarayan</a>,
<a href="author_page.cfm?id=99659283949">Griffin Page</a>,
<a href="author_page.cfm?id=81384604994">Muhammad Shahzad</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 401-413</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210335" title="DOI">10.1145/3210240.3210335</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210335&amp;ftid=1984462&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Other formats:
<a name="OtherFormatswebm" title="Other Formats webm" href="ft_gateway.cfm?id=3210335&amp;ftid=1992741&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/webm.jpg" alt="webm" class="fulltext_lnk" border="0">webm</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow31" style="display:inline;"><br><div style="display:inline">WiFi based gesture recognition has received significant attention over the past few years. However, the key limitation of prior WiFi based gesture recognition systems is that they cannot recognize the gestures of multiple users performing them simultaneously. ...</div></span>
<span id="toHide31" style="display:none;"><br><div style="display:inline"><p>WiFi based gesture recognition has received significant attention over the past few years. However, the key limitation of prior WiFi based gesture recognition systems is that they cannot recognize the gestures of multiple users performing them simultaneously. In this paper, we address this limitation and propose WiMU, a WiFi based Multi-User gesture recognition system. The key idea behind WiMU is that when it detects that some users have performed some gestures simultaneously, it first automatically determines the number of simultaneously performed gestures (Na) and then, using the training samples collected from a single user, generates virtual samples for various plausible combinations of Na gestures. The key property of these virtual samples is that the virtual samples for any given combination of gestures are identical to the real samples that would result from real users performing that combination of gestures. WiMU compares the detected sample against these virtual samples and recognizes the simultaneously performed gestures. We implemented and extensively evaluated WiMU using commodity WiFi devices. Our results show that WiMU recognizes 2, 3, 4, 5, and 6 simultaneously performed gestures with accuracies of 95.0, 94.6, 93.6, 92.6, and 90.9%, respectively.</p></div></span> <a id="expcoll31" href="JavaScript: expandcollapse('expcoll31',31)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210336">BARNET: Towards Activity Recognition Using Passive Backscattering Tag-to-Tag Network</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=81488649733">Jihoon Ryoo</a>,
<a href="author_page.cfm?id=99659146978">Yasha Karimi</a>,
<a href="author_page.cfm?id=81467641643">Akshay Athalye</a>,
<a href="author_page.cfm?id=81479661323">Milutin Stanaƒáeviƒá</a>,
<a href="author_page.cfm?id=81100148302">Samir R. Das</a>,
<a href="author_page.cfm?id=81100436022">Petar Djuriƒá</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 414-427</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210336" title="DOI">10.1145/3210240.3210336</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210336&amp;ftid=1984441&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Other formats:
<a name="OtherFormatswebm" title="Other Formats webm" href="ft_gateway.cfm?id=3210336&amp;ftid=1992731&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/webm.jpg" alt="webm" class="fulltext_lnk" border="0">webm</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow32" style="display:inline;"><br><div style="display:inline">We present the vision of BARNET (Backscattering Activity Recognition NEtwork of Tags), a network of passive RF tags that use RF backscatter for tag-to-tag communication. BARNET not only provides identification of tagged objects but also can serve as ...</div></span>
<span id="toHide32" style="display:none;"><br><div style="display:inline"><p>We present the vision of BARNET (Backscattering Activity Recognition NEtwork of Tags), a network of passive RF tags that use RF backscatter for tag-to-tag communication. BARNET not only provides identification of tagged objects but also can serve as a 'device-free' activity recognition system. BARNET's key innovation is the concept of backscatter channel state information (BCSI) which can be measured via systematic multiphase probing of the backscatter tag-to-tag channel using innovative processing on the passive tags. So far such measurements were only possible using active radio receivers that consume much higher power. Changes in BCSI provide signatures for different activities in the environment that can be learned using suitable machine learning tools. We develop the BARNET tag architecture which shows that an ASIC implementation can run on harvested RF power. We develop a printed circuit board (PCB) prototype using discrete components to evaluate activity recognition performance. We show that the prototype can recognize human daily activities with an average error around 6%. Overall, BARNET uses passive tags to achieve the same level of performance as systems that use powered, active radios.</p></div></span> <a id="expcoll32" href="JavaScript: expandcollapse('expcoll32',32)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210328">WiSh: Towards a Wireless Shape-aware World using Passive RFIDs</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99659236089">Haojian Jin</a>,
<a href="author_page.cfm?id=99659282950">Jingxian Wang</a>,
<a href="author_page.cfm?id=99659236182">Zhijian Yang</a>,
<a href="author_page.cfm?id=99659236483">Swarun Kumar</a>,
<a href="author_page.cfm?id=99659236424">Jason Hong</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 428-441</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210328" title="DOI">10.1145/3210240.3210328</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210328&amp;ftid=1984472&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Other formats:
<a name="OtherFormatswebm" title="Other Formats webm" href="ft_gateway.cfm?id=3210328&amp;ftid=1992758&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/webm.jpg" alt="webm" class="fulltext_lnk" border="0">webm</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow33" style="display:inline;"><br><div style="display:inline">This paper presents WiSh, a solution that makes ordinary surfaces shape-aware, relaying their real-time geometry directly to a user's handheld device. WiSh achieves this using inexpensive, light-weight and battery-free RFID tags attached to these surfaces ...</div></span>
<span id="toHide33" style="display:none;"><br><div style="display:inline"><p>This paper presents WiSh, a solution that makes ordinary surfaces shape-aware, relaying their real-time geometry directly to a user's handheld device. WiSh achieves this using inexpensive, light-weight and battery-free RFID tags attached to these surfaces tracked from a compact single-antenna RFID reader. In doing so, WiSh enables several novel applications: shape-aware clothing that can detect a user's posture, interactive shape-aware toys or even shape-aware bridges that report their structural health.</p> <p>WiSh's core algorithm infers the shape of ordinary surfaces using the wireless channels of signals reflected off RFID tags received at a single-antenna RFID reader. Indeed, locating every RFID tag using a single channel measurement per-tag is challenging, given that neither their 3-D coordinates nor orientation are known a priori. WiSh presents a novel algorithm that models the geometric constraints between the coordinates of the RFID tags based on flexibility of the surface upon which they are mounted. By inferring surface curvature parameters rather than the locations of individual RFID tags, we greatly reduce the number of variables our system needs to compute. Further, WiSh overcomes a variety of system-level challenges stemming from signal multipath, stretching of fabric and modeling large surfaces. We implement WiSh on commodity RFID readers and tags attached to a variety of surfaces and demonstrate mm-accurate shape-tracking across various applications.</p></div></span> <a id="expcoll33" href="JavaScript: expandcollapse('expcoll33',33)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210345">LiquID: A Wireless Liquid IDentifier</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=81443596501">Ashutosh Dhekne</a>,
<a href="author_page.cfm?id=81442609384">Mahanth Gowda</a>,
<a href="author_page.cfm?id=99659283833">Yixuan Zhao</a>,
<a href="author_page.cfm?id=81467671394">Haitham Hassanieh</a>,
<a href="author_page.cfm?id=81100078034">Romit Roy Choudhury</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 442-454</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210345" title="DOI">10.1145/3210240.3210345</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210345&amp;ftid=1984497&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Other formats:
<a name="OtherFormatswebm" title="Other Formats webm" href="ft_gateway.cfm?id=3210345&amp;ftid=1992742&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/webm.jpg" alt="webm" class="fulltext_lnk" border="0">webm</a>
</span>
</td>
</tr>
 <tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow34" style="display:inline;"><br><div style="display:inline">This paper shows the feasibility of identifying liquids by shining ultra-wideband (UWB) wireless signals through them. The core opportunity arises from the fact that wireless signals experience distinct slow-down and attenuation when passing through ...</div></span>
<span id="toHide34" style="display:none;"><br><div style="display:inline"><p>This paper shows the feasibility of identifying liquids by shining ultra-wideband (UWB) wireless signals through them. The core opportunity arises from the fact that wireless signals experience distinct slow-down and attenuation when passing through a liquid, manifesting in the phase, strength, and propagation delay of the outgoing signal. While this intuition is simple, building a robust system entails numerous challenges, including (1) pico-second scale time of flight estimation, (2) coping with integer ambiguity due to phase wraps, (3) pollution from hardware noise and multipath, and (4) compensating for the liquid-container's impact on the measurements. We address these challenges through multiple stages of signal processing without relying on any feature extraction or machine learning. Instead, we model the behavior of radio signals inside liquids (using principles of physics), and estimate the liquid's permittivity, which in turn identifies the liquid. Experiments across 33 different liquids (spread over the whole permittivity spectrum) show median permittivity error of 9%. This implies that coke can be discriminated from diet coke or pepsi, whole milk from 2% milk, and distilled water from saline water. Our end system, LiquID, is cheap, non-invasive, and amenable to real-world applications.</p></div></span> <a id="expcoll34" href="JavaScript: expandcollapse('expcoll34',34)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210312">Cross-Platform Support for Rapid Development of Mobile Acoustic Sensing Applications</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=81508682505">Yu-Chih Tung</a>,
<a href="author_page.cfm?id=87258743157">Duc Bui</a>,
<a href="author_page.cfm?id=99659283708">Kang G. Shin</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 455-467</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210312" title="DOI">10.1145/3210240.3210312</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210312&amp;ftid=1984451&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Other formats:
<a name="OtherFormatswebm" title="Other Formats webm" href="ft_gateway.cfm?id=3210312&amp;ftid=1992732&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/webm.jpg" alt="webm" class="fulltext_lnk" border="0">webm</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow35" style="display:inline;"><br><div style="display:inline">LibAS is a cross-platform framework to facilitate the rapid development of mobile acoustic sensing apps. It helps developers quickly realize their ideas by using a high-level Matlab script, and test them on various OS platforms, such as Android, iOS, ...</div></span>
<span id="toHide35" style="display:none;"><br><div style="display:inline"><p>LibAS is a cross-platform framework to facilitate the rapid development of mobile acoustic sensing apps. It helps developers quickly realize their ideas by using a high-level Matlab script, and test them on various OS platforms, such as Android, iOS, Tizen, and Linux/Win. LibAS simplifies the development of acoustic sensing apps by hiding the platform-dependent details. For example, developers need not learn Objective-C/SWIFT or the audio buffer management in the CoreAudio framework when they want to implement acoustic sensing algorithms on an iPhone. Instead, developers only need to decide on the sensing signals and the callback function to handle each repetition of sensing signals. We have implemented apps covering three major acoustic sensing categories to demonstrate the benefits and simplicity of developing apps with LibAS. Our evaluation results show the adaptability of LibAS in supporting various acoustic sensing apps and tuning/improving their performance efficiently. Developers have reported that LibAS saves them a significant amount of time/effort and can reduce up to 90% lines of code in their acoustic sensing apps.</p></div></span> <a id="expcoll35" href="JavaScript: expandcollapse('expcoll35',35)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210325">AIM: Acoustic Imaging on a Mobile</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99658719463">Wenguang Mao</a>,
<a href="author_page.cfm?id=99659284609">Mei Wang</a>,
<a href="author_page.cfm?id=99659180446">Lili Qiu</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 468-481</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210325" title="DOI">10.1145/3210240.3210325</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210325&amp;ftid=1984487&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Other formats:
<a name="OtherFormatswebm" title="Other Formats webm" href="ft_gateway.cfm?id=3210325&amp;ftid=1992733&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/webm.jpg" alt="webm" class="fulltext_lnk" border="0">webm</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow36" style="display:inline;"><br><div style="display:inline">The popularity of smartphones has grown at an unprecedented rate, which makes smartphone based imaging especially appealing. In this paper, we develop a novel acoustic imaging system using only an off-the-shelf smartphone. It is an attractive alternative ...</div></span>
<span id="toHide36" style="display:none;"><br><div style="display:inline"><p>The popularity of smartphones has grown at an unprecedented rate, which makes smartphone based imaging especially appealing. In this paper, we develop a novel acoustic imaging system using only an off-the-shelf smartphone. It is an attractive alternative to camera based imaging under darkness and obstruction. Our system is based on Synthetic Aperture Radar (SAR). To image an object, a user moves a phone along a predefined trajectory to mimic a virtual sensor array. SAR based imaging poses several new challenges in our context, including strong self and background interference, deviation from the desired trajectory due to hand jitters, and severe speaker/microphone distortion. We address these challenges by developing a 2-stage interference cancellation scheme, a new algorithm to compensate trajectory errors, and an effective method to minimize the impact of signal distortion. We implement a proof-of-concept system on Samsung S7. Our results demonstrate the feasibility and effectiveness of acoustic imaging on a mobile.</p></div></span> <a id="expcoll36" href="JavaScript: expandcollapse('expcoll36',36)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210323">Rubiks: Practical 360-Degree Streaming for Smartphones</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99659074601">Jian He</a>,
<a href="author_page.cfm?id=99659039810">Mubashir Adnan Qureshi</a>,
<a href="author_page.cfm?id=99659180446">Lili Qiu</a>,
<a href="author_page.cfm?id=99659279863">Jin Li</a>,
<a href="author_page.cfm?id=99659194185">Feng Li</a>,
<a href="author_page.cfm?id=99659194163">Lei Han</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 482-494</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210323" title="DOI">10.1145/3210240.3210323</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210323&amp;ftid=1984505&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Other formats:
<a name="OtherFormatswebm" title="Other Formats webm" href="ft_gateway.cfm?id=3210323&amp;ftid=1992754&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/webm.jpg" alt="webm" class="fulltext_lnk" border="0">webm</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow37" style="display:inline;"><br><div style="display:inline">The popularity of 360¬∞ videos has grown rapidly due to the immersive user experience. 360¬∞ videos are displayed as a panorama and the view automatically adapts with the head movement. Existing systems stream 360¬∞ videos in a similar way as ...</div></span>
<span id="toHide37" style="display:none;"><br><div style="display:inline"><p>The popularity of 360¬∞ videos has grown rapidly due to the immersive user experience. 360¬∞ videos are displayed as a panorama and the view automatically adapts with the head movement. Existing systems stream 360¬∞ videos in a similar way as regular videos, where all data of the panoramic view is transmitted. This is wasteful since a user only views a small portion of the 360¬∞ view. To save bandwidth, recent works propose the tile-based streaming, which divides the panoramic view to multiple smaller sized tiles and streams only the tiles within a user's field of view (FoV) predicted based on the recent head position. Interestingly, the tile-based streaming has only been simulated or implemented on desktops. We find that it cannot run in real-time even on the latest smartphone (e.g., Samsung S7, Samsung S8 and Huawei Mate 9) due to hardware and software limitations. Moreover, it results in significant video quality degradation due to head movement prediction error, which is hard to avoid. Motivated by these observations, we develop a novel tile-based layered approach to stream 360¬∞ content on smartphones to avoid bandwidth wastage while maintaining high video quality. Through real system experiments, we show our approach can achieve up to 69% improvement in user QoE and 49% in bandwidth savings over existing approaches. To the best of our knowledge, this is the first 360¬∞ streaming framework that takes into account the practical limitations of Android based smartphones.</p></div></span> <a id="expcoll37" href="JavaScript: expandcollapse('expcoll37',37)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3223572">Avoiding an IoT 'Tragedy of the Commons'</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=81100267354">Laura Marie Feeney</a>,
<a href="author_page.cfm?id=81100357694">Per Gunningberg</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 495-497</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3223572" title="DOI">10.1145/3210240.3223572</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3223572&amp;ftid=1984463&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow38" style="display:inline;"><br><div style="display:inline">The large number and wide diversity of IoT networks operating in unlicensed spectrum will create a complex and challenging interference environment. To avoid a 'tragedy of the commons', networks may need to more explicitly coordinate their use of the ...</div></span>
<span id="toHide38" style="display:none;"><br><div style="display:inline"><p>The large number and wide diversity of IoT networks operating in unlicensed spectrum will create a complex and challenging interference environment. To avoid a 'tragedy of the commons', networks may need to more explicitly coordinate their use of the shared channel.</p></div></span> <a id="expcoll38" href="JavaScript: expandcollapse('expcoll38',38)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3223573">I3: An IoT Marketplace for Smart Communities</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=81100463989">Bhaskar Krishnamachari</a>,
<a href="author_page.cfm?id=99659282983">Jerry Power</a>,
<a href="author_page.cfm?id=99659284305">Seon Ho Kim</a>,
<a href="author_page.cfm?id=81100616904">Cyrus Shahabi</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 498-499</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3223573" title="DOI">10.1145/3210240.3223573</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3223573&amp;ftid=1984488&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3223574">Lifelong Learning on Harvested Energy</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=81501668721">Shahriar Nirjon</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 500-501</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3223574" title="DOI">10.1145/3210240.3223574</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3223574&amp;ftid=1984473&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow40" style="display:inline;"><br><div style="display:inline">We introduce the vision of lifelong and intermittent learning, which will enable batteryless computing platforms to execute a certain class of machine learning tasks. We identify key properties and challenges to learning on harvested energy which relates ...</div></span>
<span id="toHide40" style="display:none;"><br><div style="display:inline"><p>We introduce the vision of lifelong and intermittent learning, which will enable batteryless computing platforms to execute a certain class of machine learning tasks. We identify key properties and challenges to learning on harvested energy which relates to the semantics of machine learning tasks. Each of these challenges leads to a new research direction. We envision that a big chunk of research on batteryless IoT devices in the next 5-10 years will be about making them capable of continuously learning throughout their lifetime. Concepts related to intermittent learning will be at the heart of those works.</p></div></span> <a id="expcoll40" href="JavaScript: expandcollapse('expcoll40',40)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3223570">Data Analytics Service Composition and Deployment on IoT Devices</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99659089815">Jianxin Zhao</a>,
<a href="author_page.cfm?id=99659283796">Tudor Tiplea</a>,
<a href="author_page.cfm?id=81313480954">Richard Mortier</a>,
<a href="author_page.cfm?id=81100034222">Jon Crowcroft</a>,
<a href="author_page.cfm?id=99659283683">Liang Wang</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 502-504</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3223570" title="DOI">10.1145/3210240.3223570</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3223570&amp;ftid=1984509&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3226062">Decentralised Edge-Computing and IoT through Distributed Trust</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=81326492087">Ioannis Psaras</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 505-507</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3226062" title="DOI">10.1145/3210240.3226062</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3226062&amp;ftid=1984452&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow42" style="display:inline;"><br><div style="display:inline">The emerging Internet of Things needs edge-computing - this is an established fact. In turn, edge computing needs infrastructure decentralisation. What is not necessarily established yet is that infrastructure decentralisation needs a distributed model ...</div></span>
<span id="toHide42" style="display:none;"><br><div style="display:inline"><p>The emerging Internet of Things needs edge-computing - this is an established fact. In turn, edge computing needs infrastructure decentralisation. What is not necessarily established yet is that infrastructure decentralisation needs a distributed model of Internet governance and decentralised trust schemes. We discuss the features of a decentralised IoT and edge-computing ecosystem and list the components that need to be designed, as well the challenges that need to be addressed.</p></div></span> <a id="expcoll42" href="JavaScript: expandcollapse('expcoll42',42)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3223569">Leveraging Secure Multiparty Computation in the Internet of Things</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99659257117">Marcel von Maltitz</a>,
<a href="author_page.cfm?id=81100529257">Georg Carle</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 508-510</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3223569" title="DOI">10.1145/3210240.3223569</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3223569&amp;ftid=1984442&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow43" style="display:inline;"><br><div style="display:inline">Centralized systems in the Internet of Things---be it local middleware or cloud-based services---fail to fundamentally address privacy of the collected data. We propose an architecture featuring secure multiparty computation at its core in order to realize ...</div></span>
<span id="toHide43" style="display:none;"><br><div style="display:inline"><p>Centralized systems in the Internet of Things---be it local middleware or cloud-based services---fail to fundamentally address privacy of the collected data. We propose an architecture featuring secure multiparty computation at its core in order to realize data processing systems which already incorporate support for privacy protection in the architecture.</p></div></span> <a id="expcoll43" href="JavaScript: expandcollapse('expcoll43',43)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210803">TrustGyges: A Hidden Volume Solution with Cloud Safe Storage and TEE</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99659282682">Wendi Feng</a>,
<a href="author_page.cfm?id=99659282918">Chuanchang Liu</a>,
<a href="author_page.cfm?id=84459023957">Bingfei Ren</a>,
<a href="author_page.cfm?id=99658710895">Bo Cheng</a>,
<a href="author_page.cfm?id=81408596140">Junliang Chen</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 511-511</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210803" title="DOI">10.1145/3210240.3210803</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210803&amp;ftid=1984474&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210804">Using Crowdsourcing Data for Adaptive Video Streaming in Cellular Network</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99659282685">Ermias A. Walelgne</a>,
<a href="author_page.cfm?id=99659282639">Alemnew S. Asrese</a>,
<a href="author_page.cfm?id=81557784856">Vaibhav Bajpai</a>,
<a href="author_page.cfm?id=81100112252">J√∂rg Ott</a>,
<a href="author_page.cfm?id=81100188376">Jukka Manner</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 512-512</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210804" title="DOI">10.1145/3210240.3210804</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210804&amp;ftid=1984453&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210805">A PUF Seed Generator for RIOT: Introducing Crypto-Fundamentals to the Wild</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99658984591">Peter Kietzmann</a>,
<a href="author_page.cfm?id=99659046514">Cenk G√ºndoƒüan</a>,
<a href="author_page.cfm?id=81410593321">Thomas C. Schmidt</a>,
<a href="author_page.cfm?id=81100465667">Matthias W√§hlisch</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 513-513</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210805" title="DOI">10.1145/3210240.3210805</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210805&amp;ftid=1984475&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210806">When Autonomous Drones Meet Driverless Cars</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99659283119">Qing Wang</a>,
<a href="author_page.cfm?id=99658758780">Chenren Xu</a>,
<a href="author_page.cfm?id=81329490305">Supeng Leng</a>,
<a href="author_page.cfm?id=81342507640">Sofie Pollin</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 514-514</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210806" title="DOI">10.1145/3210240.3210806</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210806&amp;ftid=1984510&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow47" style="display:inline;"><br><div style="display:inline">In this poster, we envision the promising cooperation between autonomous drones and driverless cars. We discuss potential applications and opportunities enabled by this cooperation.</div></span>
<span id="toHide47" style="display:none;"><br><div style="display:inline"><p>In this poster, we envision the promising cooperation between autonomous drones and driverless cars. We discuss potential applications and opportunities enabled by this cooperation.</p></div></span> <a id="expcoll47" href="JavaScript: expandcollapse('expcoll47',47)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210808">A Multipath Transport Multihoming Mobile Relay Architecture for High-speed Rails Networking</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99659282890">Yunzhe Ni</a>,
<a href="author_page.cfm?id=99658758780">Chenren Xu</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 515-515</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210808" title="DOI">10.1145/3210240.3210808</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210808&amp;ftid=1984454&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
</td>
</tr>
<tr>
 <td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210809">Named-data Emergency Network Services</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=81490663448">Miguel Tavares</a>,
<a href="author_page.cfm?id=99659202398">Omar Aponte</a>,
<a href="author_page.cfm?id=99659168598">Paulo Mendes</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 516-516</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210809" title="DOI">10.1145/3210240.3210809</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210809&amp;ftid=1984476&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow49" style="display:inline;"><br><div style="display:inline">This poster explains how to deploy emergency services leveraging Named-Data Networking with push communications and the capability of operating on intermittent wireless networks.</div></span>
<span id="toHide49" style="display:none;"><br><div style="display:inline"><p>This poster explains how to deploy emergency services leveraging Named-Data Networking with push communications and the capability of operating on intermittent wireless networks.</p></div></span> <a id="expcoll49" href="JavaScript: expandcollapse('expcoll49',49)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210810">Audio-Kinetic Model for Automatic Dietary Monitoring with Earable Devices</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99659283998">Chulhong Min</a>,
<a href="author_page.cfm?id=81548006572">Akhil Mathur</a>,
<a href="author_page.cfm?id=81300263201">Fahim Kawsar</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 517-517</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210810" title="DOI">10.1145/3210240.3210810</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210810&amp;ftid=1984511&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210811">Spatial Audio for Human-Object Interactions in Small AR Workspaces</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99658983074">Jing Yang</a>,
<a href="author_page.cfm?id=81453662639">G√°bor S√∂r√∂s</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 518-518</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210811" title="DOI">10.1145/3210240.3210811</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210811&amp;ftid=1984455&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow51" style="display:inline;"><br><div style="display:inline">While spatial audio has been an essential component in Virtual Reality, it has been rarely applied to Augmented Reality. We propose a concept and a prototype to enhance human-object interactions in daily life with 3D audio. We augment real objects in ...</div></span>
<span id="toHide51" style="display:none;"><br><div style="display:inline"><p>While spatial audio has been an essential component in Virtual Reality, it has been rarely applied to Augmented Reality. We propose a concept and a prototype to enhance human-object interactions in daily life with 3D audio. We augment real objects in a small workspace around the user with spatial audio notifications.</p></div></span> <a id="expcoll51" href="JavaScript: expandcollapse('expcoll51',51)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210813">Pathstore, A Data Storage Layer For The Edge</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99658677236">Seyed Hossein Mortazavi</a>,
<a href="author_page.cfm?id=81440621864">Bharath Balasubramanian</a>,
<a href="author_page.cfm?id=81100368390">Eyal de Lara</a>,
<a href="author_page.cfm?id=99659283009">Shankaranarayanan Puzhavakath Narayanan</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 519-519</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210813" title="DOI">10.1145/3210240.3210813</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210813&amp;ftid=1984464&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210814">On-Wearable AI to Model Human Interruptibility</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=81504688684">Claudio Forlivesi</a>,
<a href="author_page.cfm?id=81486655383">Marc van den Broeck</a>,
<a href="author_page.cfm?id=81336487423">Utku G√ºnay Acer</a>,
<a href="author_page.cfm?id=81300263201">Fahim Kawsar</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 520-520</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210814" title="DOI">10.1145/3210240.3210814</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210814&amp;ftid=1984489&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210815">An Accurate Smartphone Ranging System</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99659282775">Mohammadbagher Fotouhi</a>,
<a href="author_page.cfm?id=99659282416">Ruixin Niu</a>,
<a href="author_page.cfm?id=99659282610">Wei Cheng</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 521-521</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210815" title="DOI">10.1145/3210240.3210815</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210815&amp;ftid=1984490&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow54" style="display:inline;"><br><div style="display:inline">In this poster, an accurate distance ranging system for off-the-shelf smartphones is introduced. Two ranging methods, namely improved Microsoft Beep-Beep and our Single-Beep, are developed and evaluated on 6 different Android phones.</div></span>
<span id="toHide54" style="display:none;"><br><div style="display:inline"><p>In this poster, an accurate distance ranging system for off-the-shelf smartphones is introduced. Two ranging methods, namely improved Microsoft Beep-Beep and our Single-Beep, are developed and evaluated on 6 different Android phones.</p></div></span> <a id="expcoll54" href="JavaScript: expandcollapse('expcoll54',54)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210816">Exploring an Inclusive User Interface through Respiration</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99659284060">Zhuolin Yang</a>,
<a href="author_page.cfm?id=99659283458">Zhengxiong Li</a>,
<a href="author_page.cfm?id=99659283579">Yan Zhuang</a>,
<a href="author_page.cfm?id=84459579257">Wenyao Xu</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 522-522</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210816" title="DOI">10.1145/3210240.3210816</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210816&amp;ftid=1984491&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210817">Speech in Smartwatch based Audio</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99658993188">Daniyal Liaqat</a>,
<a href="author_page.cfm?id=99659051881">Robert Wu</a>,
<a href="author_page.cfm?id=99659051695">Andrea Gershon</a>,
<a href="author_page.cfm?id=99659050353">Hisham Alshaer</a>,
<a href="author_page.cfm?id=81100438784">Frank Rudzicz</a>,
<a href="author_page.cfm?id=81100368390">Eyal de Lara</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 523-523</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210817" title="DOI">10.1145/3210240.3210817</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210817&amp;ftid=1984465&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210818">Design and Implementation of Driving Information Collection System for Driver Behavior Analysis</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99659181045">Beomjun Kim</a>,
<a href="author_page.cfm?id=99659284685">Juhee Seo</a>,
<a href="author_page.cfm?id=99659282781">Jaebong Lim</a>,
<a href="author_page.cfm?id=99659284237">Yunju Baek</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 524-524</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210818" title="DOI">10.1145/3210240.3210818</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210818&amp;ftid=1984466&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210819">LightCert: Designing Smaller Certificates for the Internet of Things Devices</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99659273977">HyukSang Kwon</a>,
<a href="author_page.cfm?id=99659254070">JeongGil Ko</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 525-525</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210819" title="DOI">10.1145/3210240.3210819</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210819&amp;ftid=1984456&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210824">RaDiCS: Distributed Computing Service over Raspberry Pis with Unikernels</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99659283636">Keith Collister</a>,
<a href="author_page.cfm?id=81100344967">Eiko Yoneki</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 526-526</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210824" title="DOI">10.1145/3210240.3210824</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210824&amp;ftid=1984498&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
 </td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210820">Reactive Mesh Simplification for Augmented Reality Head Mounted Displays</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99659252068">Jaewon Choi</a>,
<a href="author_page.cfm?id=99659282503">Hyeonjung Park</a>,
<a href="author_page.cfm?id=81320493493">Jeongyeup Paek</a>,
<a href="author_page.cfm?id=99659284116">JeongGil Ko</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 527-527</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210820" title="DOI">10.1145/3210240.3210820</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210820&amp;ftid=1984512&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210821">Using Pre-trained Full-Precision Models to Speed Up Training Binary Networks For Mobile Devices</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99659284448">Milad Alizadeh</a>,
<a href="author_page.cfm?id=81320492159">Nicholas D. Lane</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 528-528</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210821" title="DOI">10.1145/3210240.3210821</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210821&amp;ftid=1984513&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow61" style="display:inline;"><br><div style="display:inline">Binary Neural Networks (BNNs) are well-suited for deploying Deep Neural Networks (DNNs) to small embedded devices but state-of-the-art BNNs need to be trained from scratch for a long time. We show how weights from a pre-trained full-precision model can ...</div></span>
<span id="toHide61" style="display:none;"><br><div style="display:inline"><p>Binary Neural Networks (BNNs) are well-suited for deploying Deep Neural Networks (DNNs) to small embedded devices but state-of-the-art BNNs need to be trained from scratch for a long time. We show how weights from a pre-trained full-precision model can be used to speed-up training of binary networks. We show that for CIFAR-10, accuracies within 1% of the full-precision model can be achieved in just 5 epochs.</p></div></span> <a id="expcoll61" href="JavaScript: expandcollapse('expcoll61',61)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210822">Deterministic binary filters for keyword spotting applications</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99659283516">Javier Fern√°ndez-Marqu√©s</a>,
<a href="author_page.cfm?id=99659284393">Vincent W.-S. Tseng</a>,
<a href="author_page.cfm?id=99659283617">Sourav Bhattachara</a>,
<a href="author_page.cfm?id=99659284310">Nicholas D. Lane</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 529-529</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210822" title="DOI">10.1145/3210240.3210822</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210822&amp;ftid=1984499&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow62" style="display:inline;"><br><div style="display:inline">We present a binary architecture with 60% fewer parameters and 50% fewer operations during inference compared to the current state of the art for keyword spotting (KWS) applications at the cost of 3.4% accuracy. We construct convolutional filters on-the-fly ...</div></span>
<span id="toHide62" style="display:none;"><br><div style="display:inline"><p>We present a binary architecture with 60% fewer parameters and 50% fewer operations during inference compared to the current state of the art for keyword spotting (KWS) applications at the cost of 3.4% accuracy. We construct convolutional filters on-the-fly using orthogonal binary codes and results in a compact architecture that would fit in devices with less than 30kB of memory.</p></div></span> <a id="expcoll62" href="JavaScript: expandcollapse('expcoll62',62)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3210823">Inference of Big-Five Personality Using Large-scale Networked Mobile and Appliance Data</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99659236294">Catherine Tong</a>,
<a href="author_page.cfm?id=99658635855">Gabriella M. Harari</a>,
<a href="author_page.cfm?id=99658976086">Angela Chieh</a>,
<a href="author_page.cfm?id=99659236746">Otmane Bellahsen</a>,
<a href="author_page.cfm?id=99659237281">Matthieu Vegreville</a>,
<a href="author_page.cfm?id=99659260963">Eva Roitmann</a>,
<a href="author_page.cfm?id=81320492159">Nicholas D. Lane</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 530-530</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3210823" title="DOI">10.1145/3210240.3210823</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3210823&amp;ftid=1984477&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow63" style="display:inline;"><br><div style="display:inline">We present the first large-scale (9270-user) study of data from both mobile and networked appliances for Big-Five personality inference. We correlate aggregated behavioral and physical health features with personalities, and perform binary classification ...</div></span>
<span id="toHide63" style="display:none;"><br><div style="display:inline"><p>We present the first large-scale (9270-user) study of data from both mobile and networked appliances for Big-Five personality inference. We correlate aggregated behavioral and physical health features with personalities, and perform binary classification using SVM and Decision Tree. We find that it is possible to infer each Big-Five personality at accuracies of 75% from this dataset despite its size and complexity (mix of mobile and appliance) as prior methods offer similar accuracy levels. We would like to achieve better accuracies and this study is a first step towards seeing how to model such data.</p></div></span> <a id="expcoll63" href="JavaScript: expandcollapse('expcoll63',63)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3211119">Touchless Wireless Authentication via LocalVLC</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99659046179">Michael Haus</a>,
<a href="author_page.cfm?id=81557313856">Aaron Yi Ding</a>,
<a href="author_page.cfm?id=99658758780">Chenren Xu</a>,
<a href="author_page.cfm?id=81100112252">J√∂rg Ott</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 531-531</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3211119" title="DOI">10.1145/3210240.3211119</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3211119&amp;ftid=1984478&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3211106">CAR: The Cleanest Air Routing Algorithm for Path Navigation with Minimal PM2.5 Exposure on the Move</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99659052411">Sachit Mahajan</a>,
<a href="author_page.cfm?id=99659282617">Yu-Siou Tang</a>,
<a href="author_page.cfm?id=99659284930">Dong-Yi Wu</a>,
<a href="author_page.cfm?id=99659283937">Tzu-Chieh Tsai</a>,
<a href="author_page.cfm?id=99659284096">Ling-Jyh Chen</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 532-532</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3211106" title="DOI">10.1145/3210240.3211106</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3211106&amp;ftid=1984479&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3211107">A Novel Finger-Assisted Touch-free Text Input System Without Training</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99659284026">Qiang Yang</a>,
<a href="author_page.cfm?id=99659282795">Hongrui Fu</a>,
<a href="author_page.cfm?id=99659148034">Yongpan Zou</a>,
<a href="author_page.cfm?id=99658758603">Kaishun Wu</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 533-533</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3211107" title="DOI">10.1145/3210240.3211107</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3211107&amp;ftid=1984492&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow66" style="display:inline;"><br><div style="display:inline">Recently, tiny smart devices have become increasingly popular in our lives because of their neat features and stylish appearance. However, their small form factors, especially screens, make it inconvenient for users to enter texts with conventional methods ...</div></span>
<span id="toHide66" style="display:none;"><br><div style="display:inline"><p>Recently, tiny smart devices have become increasingly popular in our lives because of their neat features and stylish appearance. However, their small form factors, especially screens, make it inconvenient for users to enter texts with conventional methods such as soft keyboards, which need a fairly large screen. To address this problem, we propose a novel texts-input system, called EchoType, with which users can enter texts with a finger writing in the air. EchoType makes use of acoustic sensors (i.e., microphone and speaker) to sense finger gestures and infer texts based on mapping relation between gestures and basic letters. We take a step to enable users to input texts with acoustic signals. Compared with existing approaches, EchoType enjoys merits of low hardware requirements and high scalability to different mobile devices.</p></div></span> <a id="expcoll66" href="JavaScript: expandcollapse('expcoll66',66)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3211108">Empath-D: VR-based Empathetic App Design for Accessibility</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99659071883">Wonjung Kim</a>,
<a href="author_page.cfm?id=99659052376">Kenny Tsu Wei Choo</a>,
<a href="author_page.cfm?id=99659132136">Youngki Lee</a>,
<a href="author_page.cfm?id=81100342304">Archan Misra</a>,
<a href="author_page.cfm?id=81100050092">Rajesh Krishna Balan</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 534-534</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3211108" title="DOI">10.1145/3210240.3211108</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3211108&amp;ftid=1984480&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Other formats:
<a name="OtherFormatswebm" title="Other Formats webm" href="ft_gateway.cfm?id=3211108&amp;ftid=1992743&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/webm.jpg" alt="webm" class="fulltext_lnk" border="0">webm</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3211120">VolksFlow: Crowd Mobility Analytics with Multi-modal Data for Internet-of-Things Services</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=81558091356">G√ºrkan Solmaz</a>,
<a href="author_page.cfm?id=99659284125">Fang-Jing Wu</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 535-535</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3211120" title="DOI">10.1145/3210240.3211120</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3211120&amp;ftid=1984443&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow68" style="display:inline;"><br><div style="display:inline">VolksFlow is a real-time crowd mobility analytics system deployed in two pilot sites in New Zealand. In this demo we showcase real-time data analytics results from Wellington Railway Station. VolksFlow addresses the crowd estimation problem in a target ...</div></span>
<span id="toHide68" style="display:none;"><br><div style="display:inline"><p>VolksFlow is a real-time crowd mobility analytics system deployed in two pilot sites in New Zealand. In this demo we showcase real-time data analytics results from Wellington Railway Station. VolksFlow addresses the crowd estimation problem in a target area and provides an internet-of-things (IoT) service to share crowd estimation results across different applications. VolksFlow consists of three data analytics modules for analyzing crowd size, stay duration, and people flow. Our research for crowd estimation is based on correlating the Wi-Fi probes data with stereoscopic cameras to count people at specified "choke points".</p></div></span> <a id="expcoll68" href="JavaScript: expandcollapse('expcoll68',68)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3211109">Wireless Video Streaming for Ultra-low-power Cameras</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99659070889">Mehrdad Hessar</a>,
<a href="author_page.cfm?id=99658747101">Saman Naderiparizi</a>,
<a href="author_page.cfm?id=99659284822">Ye Wang</a>,
<a href="author_page.cfm?id=99659282351">Ali Saffari</a>,
<a href="author_page.cfm?id=81336489396">Shyamnath Gollakota</a>,
<a href="author_page.cfm?id=82659111457">Joshua R. Smith</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 536-536</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3211109" title="DOI">10.1145/3210240.3211109</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3211109&amp;ftid=1984457&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow69" style="display:inline;"><br><div style="display:inline">Wireless video streaming has traditionally been considered an extremely power-hungry operation. Existing approaches optimize the camera and communication modules individually to minimize their power consumption. However, designing a video streaming device ...</div></span>
<span id="toHide69" style="display:none;"><br><div style="display:inline"><p>Wireless video streaming has traditionally been considered an extremely power-hungry operation. Existing approaches optimize the camera and communication modules individually to minimize their power consumption. However, designing a video streaming device requires power-consuming hardware components and video CODEC algorithms which makes battery-free video streaming currently infeasible. Existing RF-powered wireless camera prototypes require extensive duty-cycling on the order of tens of minutes, to capture, process and communicate a single frame. Self-powered cameras can capture an image once every few seconds, but do not have the capability to stream video wirelessly.</p> <p>To understand this case, let us look at the different components in a video-streaming device 1(a): optical lens, video compression and communication. Optical lens is an array of photo-diodes connected to amplifiers and an ADC to translate the analog pixels into digital values. A video CODEC then performs frame compression to compress video, which is then transmitted on the wireless medium. Existing approaches optimize the camera and communication modules separately to minimize their power consumption. However, designing a video streaming device requires power consuming hardware components and video CODEC algorithms that interface the camera and the communication modules.</p> <p>We present the design of an ultra-low-power video streaming device 1(b). We create "analog" video backscatter system that does not use amplifiers, ADCs and AGCs. At a high level, we feed analog pixels from the photo-diodes directly to the backscatter hardware. We achieve this by connecting the antenna to an array of photo-diodes whose output voltage/impedance varies as a function of the pixel value; thus, eliminate power-hungry hardware components including amplifiers, AGCs and ADCs. Such an approach would have the added benefit that the video quality scales smoothly with a varying wireless channel, without the need for explicit rate adaptation. We present our video streaming architecture with more details in [1, 2].</p> <p>We implement a prototype of our backscatter design on an ultra-low power FPGA platform using a 112 √ó 112 gray-scale random pixel access camera from CentEye, which provides readout access to the individual analog pixels. The prototype of our video streaming device burns as low as 2.36 mW while streaming live video at 13 fps. Our access point (AP) consist of two components. We use RTL2832U SDR to receive backsactter signal from the tag and Semtech SX1232 and SE2435L-EK5 power amplifier to generate helper signal. We demonstrate real-time display of video frames using Python scripts which interfaces with the SDR. We evaluate our prototype under different conditions to study its performance under different room lighting conditions and different distances from the access point. We can stream at 7-13 frames per second at distances of up to 27 feet from the AP. We show a video of our real-time demonstration in following link.</p></div></span> <a id="expcoll69" href="JavaScript: expandcollapse('expcoll69',69)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3211121">Empowering Cyber-Physical Systems with FADEX</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99659043373">Vittorio Cozzolino</a>,
<a href="author_page.cfm?id=81557313856">Aaron Yi Ding</a>,
<a href="author_page.cfm?id=99659181220">Ardalan Amiri Sani</a>,
<a href="author_page.cfm?id=81313480954">Richard Mortier</a>,
<a href="author_page.cfm?id=81314490303">Dirk Kutscher</a>,
<a href="author_page.cfm?id=81100112252">J√∂rg Ott</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 537-537</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3211121" title="DOI">10.1145/3210240.3211121</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3211121&amp;ftid=1984444&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3211110">Cross-Technology Interference Nulling for Improved LTE-U/WiFi Coexistence</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99658709729">Piotr Gaw≈Çowicz</a>,
<a href="author_page.cfm?id=81315492750">Anatolij Zubow</a>,
<a href="author_page.cfm?id=81342489032">Suzan Bayhan</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 538-538</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3211110" title="DOI">10.1145/3210240.3211110</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3211110&amp;ftid=1984493&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow71" style="display:inline;"><br><div style="display:inline">Smart antennas can unlock the potential of unlicensed spectrum by letting the coexisting networks transmit concurrently without harmful interference. This is possible by strategically allocating the antenna degrees-of-freedom for both beamforming toward ...</div></span>
<span id="toHide71" style="display:none;"><br><div style="display:inline"><p>Smart antennas can unlock the potential of unlicensed spectrum by letting the coexisting networks transmit concurrently without harmful interference. This is possible by strategically allocating the antenna degrees-of-freedom for both beamforming toward the intended receiver and interference nulling toward the victim receiver(s). Our solution, named Xzero, achieves this goal for the particular case of LTE-unlicensed (LTE-U) and WiFi by overcoming the challenges of cross-technology interference nulling by a null search at the LTE-U BS with assistance from the WiFi network. Our demo shows a running prototype of Xzero implemented using USRP SDR platform running srsLTE and commodity WiFi hardware. We illustrate the change in the airtime of colocated WiFi and LTE-U networks upon activation of Xzero and fast reconfiguration of the null beam upon a change in WiFi node's location.</p></div></span> <a id="expcoll71" href="JavaScript: expandcollapse('expcoll71',71)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3211111">System-E: Enhancing Privacy on Mobile Systems through Content-Based Classification and Storage</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99658736902">Sharath Chandrashekhara</a>,
<a href="author_page.cfm?id=84459061857">Taeyeon Ki</a>,
<a href="author_page.cfm?id=81100400426">Karthik Dantu</a>,
<a href="author_page.cfm?id=83358817957">Steven Y. Ko</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 539-539</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3211111" title="DOI">10.1145/3210240.3211111</a></span></td> 
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3211111&amp;ftid=1984500&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow72" style="display:inline;"><br><div style="display:inline">Mobile systems face privacy challenges including coarsegrained privacy control and the inability to distinguish private and public files. We propose System-E, a novel system which can enhance the user privacy on mobile systems (e.g., Android) by (1) ...</div></span>
<span id="toHide72" style="display:none;"><br><div style="display:inline"><p>Mobile systems face privacy challenges including coarsegrained privacy control and the inability to distinguish private and public files. We propose System-E, a novel system which can enhance the user privacy on mobile systems (e.g., Android) by (1) enabling users to set finer grained permissions for apps accessing data, and (2) enabling automatic classification of data (e.g., photos) at the storage layer (e.g., by using deep learning) to prevent potentially sensitive data from being stored/accessed with open permissions.</p></div></span> <a id="expcoll72" href="JavaScript: expandcollapse('expcoll72',72)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3211112">Distributed Real-Time Generative 3D Hand Tracking using Edge GPGPU Acceleration</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99659184602">Ammar Qammaz</a>,
<a href="author_page.cfm?id=81500663836">Sokol Kosta</a>,
<a href="author_page.cfm?id=81484658427">Nikolaos Kyriazis</a>,
<a href="author_page.cfm?id=81100112810">Antonis Argyros</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 540-540</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3211112" title="DOI">10.1145/3210240.3211112</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3211112&amp;ftid=1984467&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow73" style="display:inline;"><br><div style="display:inline">This work demonstrates a real-time 3D hand tracking application that runs via computation offloading. The proposed framework enables the application to run on low-end mobile devices such as laptops and tablets, despite the fact that they lack the sufficient ...</div></span>
<span id="toHide73" style="display:none;"><br><div style="display:inline"><p>This work demonstrates a real-time 3D hand tracking application that runs via computation offloading. The proposed framework enables the application to run on low-end mobile devices such as laptops and tablets, despite the fact that they lack the sufficient hardware to perform the required computations locally. The network connection takes the place of a GPGPU accelerator and sharing resources with a larger workstation becomes the acceleration mechanism. The unique properties of a generative optimizer are examined and constitute a challenging use-case, since the requirement for real-time performance makes it very latency-sensitive.</p></div></span> <a id="expcoll73" href="JavaScript: expandcollapse('expcoll73',73)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3211113">eSense: Earable Platform for Human Sensing</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=81300263201">Fahim Kawsar</a>,
<a href="author_page.cfm?id=99659283998">Chulhong Min</a>,
<a href="author_page.cfm?id=81548006572">Akhil Mathur</a>,
<a href="author_page.cfm?id=81486655383">Marc Van den Broeck</a>,
<a href="author_page.cfm?id=81336487423">Utku G√ºnay Acer</a>,
<a href="author_page.cfm?id=81504688684">Claudio Forlivesi</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 541-541</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3211113" title="DOI">10.1145/3210240.3211113</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3211113&amp;ftid=1984481&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3211114">Seamless Producer Mobility for the Industrial Information-Centric Internet</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99659046514">Cenk G√ºndoƒüan</a>,
<a href="author_page.cfm?id=99658984591">Peter Kietzmann</a>,
<a href="author_page.cfm?id=81410593321">Thomas C. Schmidt</a>,
<a href="author_page.cfm?id=99658716959">Martine Lenders</a>,
<a href="author_page.cfm?id=87959341257">Hauke Petersen</a>,
<a href="author_page.cfm?id=81100465667">Matthias W√§hlisch</a>,
<a href="author_page.cfm?id=89558729457">Michael Frey</a>,
<a href="author_page.cfm?id=99659202089">Felix Shzu-Juraschek</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 542-542</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3211114" title="DOI">10.1145/3210240.3211114</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
 Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3211114&amp;ftid=1984514&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3211115">Software-defined Visible Light Backscatter Network</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99659208299">Xieyang Xu</a>,
<a href="author_page.cfm?id=99659207279">Yang Shen</a>,
<a href="author_page.cfm?id=99659208259">Guojun Chen</a>,
<a href="author_page.cfm?id=99659283684">Yue Wu</a>,
<a href="author_page.cfm?id=99659283951">Lilei Feng</a>,
<a href="author_page.cfm?id=99659283119">Qing Wang</a>,
<a href="author_page.cfm?id=99658758780">Chenren Xu</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 543-543</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3211115" title="DOI">10.1145/3210240.3211115</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3211115&amp;ftid=1984445&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow76" style="display:inline;"><br><div style="display:inline">We introduce PassiveVLN, a flexible, modular and software-defined platform for visible light backscatter networks. PassiveVLN incorporates a modular hardware design and a full-stack software implementation, enabling convenient and scalable deployment ...</div></span>
<span id="toHide76" style="display:none;"><br><div style="display:inline"><p>We introduce PassiveVLN, a flexible, modular and software-defined platform for visible light backscatter networks. PassiveVLN incorporates a modular hardware design and a full-stack software implementation, enabling convenient and scalable deployment as well as rapid prototyping for testing new protocols and applications.</p></div></span> <a id="expcoll76" href="JavaScript: expandcollapse('expcoll76',76)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3211116">Plug &amp; Play Network Application Chaining for Multi-Service Programmability in 5G RAN</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=81100579219">Navid Nikaein</a>,
<a href="author_page.cfm?id=99659283025">Chia-Yu Chang</a>,
<a href="author_page.cfm?id=99659282850">Robert Schmidt</a>,
<a href="author_page.cfm?id=99659198120">Shahab Shariat</a>,
<a href="author_page.cfm?id=99659075114">Konstantinos Alexandris</a>,
<a href="author_page.cfm?id=99659283450">Xenofon Vasilakos</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 544-544</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3211116" title="DOI">10.1145/3210240.3211116</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3211116&amp;ftid=1984506&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow77" style="display:inline;"><br><div style="display:inline">RAN slicing is one of the key enabler to enable virtualization of a BS and its delivery as a service with different levels of network isolation and sharing so as to accommodate the needs of mobile network operators and verticals. In this demonstration, ...</div></span>
<span id="toHide77" style="display:none;"><br><div style="display:inline"><p>RAN slicing is one of the key enabler to enable virtualization of a BS and its delivery as a service with different levels of network isolation and sharing so as to accommodate the needs of mobile network operators and verticals. In this demonstration, we show a prototype of a RAN slicing runtime system to enable flexible slice customization on the top of a disaggregated RAN infrastructure [1] with different levels of isolation and sharing in terms of resources and network functions, while retaining the quality of service (QoS) for different slice instances. Furthermore, a novel plug &amp; play network application chaining framework empowered by a network software development kit (SDK) is demonstrated to show how the multi-service programmability on per-slice basis can be achieved. Our demonstration is based on the OpenAirlnterface [3], Mosaic-5G FlexRAN [4] and LL-MEC [2] platforms. Finally, we highlight how the the proposed approach can be extended to an end-to-end network slicing scenario.</p></div></span> <a id="expcoll77" href="JavaScript: expandcollapse('expcoll77',77)">expand</a>
</div>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3211117">HomeMeld: Co-present Robotic Avatar System for Illusion of Living Together</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99658690166">Bumsoo Kang</a>,
<a href="author_page.cfm?id=99659284162">Inseok Hwang</a>,
<a href="author_page.cfm?id=99659284549">Jinho Lee</a>,
<a href="author_page.cfm?id=99659283804">Seungchul Lee</a>,
<a href="author_page.cfm?id=99659282681">Taegyeong Lee</a>,
<a href="author_page.cfm?id=99659284382">Youngjae Chang</a>,
<a href="author_page.cfm?id=99659283293">Min Kyung Lee</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 545-545</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3211117" title="DOI">10.1145/3210240.3211117</a></span></td>
 </tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3211117&amp;ftid=1984446&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=3211118">Video: Enabling Public Cameras to Talk to the Public</a></span></td>
</tr>
<tr>
<td> </td>
<td>
<span style="padding-left:0">
<a href="author_page.cfm?id=99659284781">Siyuan Cao</a>,
<a href="author_page.cfm?id=99659283934">Habiba Farrukh</a>,
<a href="author_page.cfm?id=99659284604">He Wang</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">Pages: 546-546</span></td>
</tr>
<tr>
<td></td>
<td> <span style="padding-left:0">doi&gt;<a href="https://doi.org/10.1145/3210240.3211118" title="DOI">10.1145/3210240.3211118</a></span></td>
</tr>
<tr>
<td></td>
<td>
<span style="padding-left:0">
Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3211118&amp;ftid=1984482&amp;dwn=1&amp;CFID=109014009&amp;CFTOKEN=f9c512663baf03d8-EF44007D-DC99-EA1C-7ABCB1CB9FA9DEA7" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0">PDF</a>
</span>
</td>
</tr>
<tr>
<td></td>
<td style="padding-bottom:15px;">
<div style="padding-left:0">
<span id="toShow79" style="display:inline;"><br><div style="display:inline">This video presents a real-time end-to-end system which enables cameras to send personalized messages to people in a public area without knowing any addresses of their mobile phones. For facilitating this communication, we solve the problem of digitally ...</div></span>
<span id="toHide79" style="display:none;"><br><div style="display:inline"><p>This video presents a real-time end-to-end system which enables cameras to send personalized messages to people in a public area without knowing any addresses of their mobile phones. For facilitating this communication, we solve the problem of digitally associating people in the camera view with their smartphones without prior knowledge of the phones' IP/MAC addresses. The system doesn't need any dedicated devices and doesn't request people to wear digital tags. It utilizes users' motion patterns and leverages the diversity in motion features as the address for communication. The cameras broadcast a message to all the phones in the camera view using the target's motion features as the destination. Then a user's phone can locally compare the "motion address" of the packet against its own sensor data and will accept the packet if it's a "good" match. To protect the privacy of users' sensor data, we keep the users' personal sensing data on their phones instead of asking them to upload the data to server. Moreover, to prevent users' walking behavior from being revealed to public, we transform the raw motion features via principal component analysis (PCA) while maintaining their distinguishing power. On the whole, our system achieves 98%, 95%, 90%, 90%, 87% matching correctness for 2, 4, 6, 8 and 10 users respectively.</p></div></span> <a id="expcoll79" href="JavaScript: expandcollapse('expcoll79',79)">expand</a>
</div>
</td>
</tr>
</tbody></table>
</div>
</div></div>